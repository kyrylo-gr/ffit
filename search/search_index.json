{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"FFit. Fit python library.","text":"<p><code>FFit</code> - Python library for easier fitting.</p>"},{"location":"#install","title":"Install","text":"<p><code>pip install ffit</code></p> <p>For more installation details, please refer to the How to install</p>"},{"location":"#how-to-use","title":"How to use","text":"<p>The aim of this library is to simplify the fit routine. Here are some examples of how to use it.</p>"},{"location":"#simple-syntax","title":"Simple syntax","text":"<pre><code>import ffit as ff\n\nx = np.linspace(1, 10, 100)\ny = 2 * np.sin(x) + 3\n\nres = ff.Cos().fit(x, y).res\n</code></pre>"},{"location":"#plotting-result","title":"Plotting result","text":"<pre><code>import ffit as ff\nimport matplotlib.pyplot as plt\n\nx = np.linspace(1, 10, 100)\ny = 2 * np.sin(x) + 3\n\nplt.plot(x, y, '.')\n\nres = ff.Cos().fit(x, y).plot().res\n</code></pre>"},{"location":"#plotting-guess","title":"Plotting guess","text":"<p>The quality of fitting is heavily dependent on the initial guess. This library provides initial guesses for various popular functions to ensure effectiveness. However, if something goes awry, you can verify the guess and set it manually.</p> <pre><code>ff.Cos().guess(x, y).plot()\n\nff.Cos().guess(x, y, guess=[1,2,3,4]).plot()\n\nff.Cos().fit(x, y, guess=[1,2,3,4]).plot()\n</code></pre>"},{"location":"#other-functions","title":"Other functions","text":"<p>Numerous functions are available out of the box. You can refer to the documentation for more details.</p> <p>Moreover, you can use your custom functions with familiar syntax and still benefit from existing routines.</p>"},{"location":"about/","title":"Overview on <code>FFit</code>.","text":""},{"location":"about/#overall-motivation","title":"Overall motivation","text":"<p>The basic motivation can be divided into two parts:</p> <ul> <li>First, the current process of fitting with <code>scipy.optimize.curve_fit</code> is too lengthy and writing-code-consuming, while it should be straightforward.</li> <li>Second, with new technology like <code>JAX</code> for python; <code>ocl</code> or <code>wgpu</code> for <code>rust</code>, we can accelerate matrix multiplication, thus probably making the entire algorithm faster.</li> </ul> <p>The first problem can be easily solved with a few hundred lines of code. Therefore, this overview will primarily focus on the second problem: How can we speed up the algorithm?</p> <p>Spoiler alert: there's a possible potential to speed up the runtime. However, due to my time constraints or impossibility, it hasn't been completed yet.</p>"},{"location":"about/#speed-up-the-algorithm","title":"Speed up the algorithm","text":"<p>Classically to fit some function you would use <code>scipy.optimize.curve_fit</code> or even <code>scipy.optimize.leastsq</code> method. The first is a wrap of the second and them both are using the Levenberg-Marquardt Algorithm by default in the backend. It uses numpy library and MINPACK solver written on Fortran.</p> <p>To make it faster one can use JAX. It uses CPU/TPU for matrix multiplication and has fast gradient calculating routine.</p>"},{"location":"about/#existed-solutions","title":"Existed solutions","text":"<p>Several solutions already exist for this problem, with diverse implementations of the Levenberg\u2013Marquardt algorithm, some of which utilize the Trust Region Method.</p> <p>The first solution is the JAXfit library, developed by the University of Oxford. According to their paper, their library is ten times faster than the scipy method. However, I wasn't able to reproduce this result on my Mac with an M1 chip using different dataset lengths.</p> <p>The second solution I found is JAXOPT, developed by Google. In their paper, they demonstrate a decrease in runtime by a factor of four on large datasets using a powerful GPU. Despite this claim, I was unable to reproduce these results on my M1 Mac. Moreover, upon closer inspection, I noticed that the jaxopt library runs the function more frequently than the classical scipy, suggesting that their algorithm may not be as optimized.</p> <p>It's worth noting that JAXOPT is currently transitioning to the new OPTAX library. However, as of now, the Levenberg\u2013Marquardt algorithm is not available there.</p> <p>With all this in mind, it motivated to explore ways to run functions faster than the traditional Python with Numpy. This is because, it still could be possible that without a powerful GPU and super-large datasets, Python and Numpy might already be quite optimized.</p>"},{"location":"about/#speed-performance-numba-vs-jax","title":"Speed performance. Numba vs JAX","text":"<p>There are various ways to enhance the speed of Python code execution. One of the most popular methods is using Just-in-Time (JIT) compilers. When you run a typical Python code for the first time, the JIT compiler analyzes and compiles the code to make it faster for subsequent runs. Numba, a library that compiles your code to the CPU, is quite popular in this regard. However, JAX also has a JIT compiler and leverages the GPU for further calculations.</p> <p>We are interested in comparing their performances. We test a classic trigonometric function with some matrix multiplications. For the dataset length, we chose 10,000 which is a quite large dataset for classical physics computations, but could highlight any GPU advantages over the CPU.</p> <p>We are interested in comparing their performances. We test a classic trigonometric function with some matrix multiplications. For the dataset length, we chose 10,000 which is a quite large dataset for classical physics computations, but could highlight any GPU advantages over the CPU.</p>"},{"location":"about/#matrix-sum","title":"Matrix sum","text":"[See details] <pre><code>import jax.numpy as jnp\nfrom numba import njit\nimport numpy as np\nfrom jax import jit as jax_jit\n\n@jax_jit\ndef jax_function(x):\n    res = jnp.copy(x)\n    for _ in range(100):\n        res += x\n    return res\n\n@njit\ndef numba_function(x):\n    res = np.copy(x)\n    for _ in range(100):\n        res += x\n    return res\n\n# Example data\nx0 = np.random.rand(1_000_000).reshape(1000, 1000)\nx_jax = jnp.array(x0)\nx_numba = np.array(x0)\n\n# Compile functions\njax_function(x_jax)\nnumba_function(x_numba)\n\n# time the functions\n%timeit jax_function(x_jax)\n# 3.31 ms \u00b1 290 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n%timeit numba_function(x_numba)\n# 44.1 ms \u00b1 3.85 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n</code></pre>"},{"location":"about/#martix-product","title":"Martix product","text":"[See details] <pre><code>import jax.numpy as jnp\nfrom numba import njit\nimport numpy as np\nfrom jax import jit as jax_jit\n\n@jax_jit\ndef jax_function(x):\n    res = jnp.copy(x)\n    for _ in range(100):\n        res += jnp.sin(x) @ jnp.cos(x)\n    return res\n\n@njit\ndef numba_function(x):\n    res = np.copy(x)\n    for _ in range(100):\n        res += np.sin(x) @ np.cos(x)\n    return res\n\n# Example data\nx0 = np.random.rand(1_000_000).reshape(1000, 1000)\nx_jax = jnp.array(x0)\nx_numba = np.array(x0)\n\n# Compile functions\njax_function(x_jax)\nnumba_function(x_numba)\n\n# time the functions\n%timeit jax_function(x_jax)\n# 19.3 ms \u00b1 237 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n\n%timeit numba_function(x_numba)\n# 7.28 s \u00b1 1.44 s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n</code></pre>"},{"location":"about/#martix-product-on-small-arrays","title":"Martix product on small arrays","text":"[See details] <pre><code>import jax.numpy as jnp\nfrom numba import njit\nimport numpy as np\nfrom jax import jit as jax_jit\n\n@jax_jit\ndef jax_function(x):\n    res = jnp.copy(x)\n    for _ in range(100):\n        res += jnp.sin(x) @ jnp.cos(x)\n    return res\n\n@njit\ndef numba_function(x):\n    res = np.copy(x)\n    for _ in range(100):\n        res += np.sin(x) @ np.cos(x)\n    return res\n\n# Example data\nx0 = np.random.rand(100).reshape(10, 10)\nx_jax = jnp.array(x0)\nx_numba = np.array(x0)\n\n# Compile functions\njax_function(x_jax)\nnumba_function(x_numba)\n\n# time the functions\n%timeit jax_function(x_jax)\n# 12.5 \u00b5s \u00b1 1.89 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100,000 loops each)\n\n%timeit numba_function(x_numba)\n# 233 \u00b5s \u00b1 3.06 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)\n</code></pre>"},{"location":"about/#need-of-jax-jit-compiling","title":"Need of JAX JIT compiling","text":"[See details] <pre><code>import jax.numpy as jnp\nfrom numba import njit\nimport numpy as np\nfrom jax import jit as jax_jit\n\n@jax.jit\ndef jax_function_nocc(x):\n    res = jnp.copy(x)\n    for _ in range(100):\n        res += jnp.sin(x) @ jnp.cos(x)\n    return res\n\n@jax.jit\ndef jax_function_compile(x):\n    res = jnp.copy(x)\n    for _ in range(100):\n        res += jnp.sin(x) @ jnp.cos(x)\n    return res\n\n# Compile functions\n\njax_function_nocc(x_jax)\njax_function_compile(x_jax)\n\n# time the functions\n\n%timeit jax_function_nocc(x_jax)\n%timeit jax_function_compile(x_jax)\n</code></pre>"},{"location":"custom_function/","title":"Custom Function","text":""},{"location":"custom_function/#curve_fit","title":"<code>curve_fit</code>","text":"<p>Fit a curve with curve_fit method.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>fit_func</code> <p>Function to fit.</p> required <code>x</code> <code>_NDARRAY</code> <p>x data.</p> required <code>data</code> <code>_NDARRAY</code> <p>data to fit.</p> required <code>p0</code> <code>Optional[List[Any]]</code> <p>Initial guess for the parameters.</p> <code>None</code> <code>bounds</code> <code>Optional[Union[List[Tuple[Any, Any]], Tuple[Any, Any]]]</code> <p>Bounds for the parameters.</p> <code>(-inf, inf)</code> <code>**kwargs</code> <p>Additional keyword arguments to curve_fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>FitResult</code> <p>Fit result.</p> Source code in <code>ffit/front.py</code> <pre><code>def curve_fit(\n    func: _t.Callable,\n    x: _NDARRAY,\n    data: _NDARRAY,\n    p0: _t.Optional[_t.List[_t.Any]] = None,\n    *,\n    bounds: _t.Optional[\n        _t.Union[_t.List[_t.Tuple[_t.Any, _t.Any]], _t.Tuple[_t.Any, _t.Any]]\n    ] = (\n        -np.inf,\n        np.inf,\n    ),\n    method: _t.Literal[\"leastsq\", \"curve_fit\"] = \"curve_fit\",\n    **kwargs,\n) -&gt; FitResult:\n    \"\"\"Fit a curve with curve_fit method.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        fit_func: Function to fit.\n        x: x data.\n        data: data to fit.\n        p0: Initial guess for the parameters.\n        bounds: Bounds for the parameters.\n        **kwargs: Additional keyword arguments to curve_fit.\n\n    Returns:\n        FitResult: Fit result.\n    \"\"\"\n    res = _curve_fit(func, x, data, p0=p0, bounds=bounds, method=method, **kwargs)\n    res = np.asarray(res)\n\n    # Get ordered parameter names\n    args_default = get_function_args_ordered(func)[1:]\n    args_ordered = tuple(key for key, _ in args_default)\n    values_ordered = tuple(val for _, val in args_default)\n\n    if len(res) != len(values_ordered):\n        res = np.concatenate([res, values_ordered[len(res) :]])\n\n    return FitResult(\n        res,\n        lambda x: func(x, *res),\n        x=x,\n        data=data,\n        keys=args_ordered,\n    )\n</code></pre>"},{"location":"fit_result/","title":"Fit result","text":""},{"location":"fit_result/#ffit.fit_results.FitResult","title":"ffit.fit_results.FitResult","text":"<p>               Bases: <code>Generic[_T]</code></p> <p>This class represents the result of a fit operation.</p>"},{"location":"fit_result/#ffit.fit_results.FitResult--examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; import ffit as ff\n&gt;&gt;&gt; result = ff.Cos().fit(x, y)\n&gt;&gt;&gt; result.res.amplitude # to get the amplitude\n&gt;&gt;&gt; result.res # to get whole result as a NamedTuple\n&gt;&gt;&gt; y0 = result.res_func(x0) # to get the fitted values\n&gt;&gt;&gt; result.plot() # to plot the fit results\n\nAll in one:\n&gt;&gt;&gt; amp = ff.Cos().fit(x, y).plot().res.amplitude\n</code></pre> <p>Methods:</p> Name Description <code>plot</code> <p>Plot the fit results on the given axes.</p> Source code in <code>ffit/fit_results.py</code> <pre><code>class FitResult(_t.Generic[_T]):\n    \"\"\"This class represents the result of a fit operation.\n\n    Examples\n    --------\n        &gt;&gt;&gt; import ffit as ff\n        &gt;&gt;&gt; result = ff.Cos().fit(x, y)\n        &gt;&gt;&gt; result.res.amplitude # to get the amplitude\n        &gt;&gt;&gt; result.res # to get whole result as a NamedTuple\n        &gt;&gt;&gt; y0 = result.res_func(x0) # to get the fitted values\n        &gt;&gt;&gt; result.plot() # to plot the fit results\n\n        All in one:\n        &gt;&gt;&gt; amp = ff.Cos().fit(x, y).plot().res.amplitude\n\n    \"\"\"\n\n    res_array: _NDARRAY\n    keys: _t.Tuple[str, ...]\n    res_func: _t.Callable[[_NDARRAY], _NDARRAY]\n    x: _t.Optional[_NDARRAY]\n    data: _t.Optional[_NDARRAY]\n    cov: _t.Optional[_NDARRAY]\n\n    stderr: _NDARRAY\n    stdfunc: _t.Callable[[_NDARRAY], _NDARRAY]\n\n    param_class: _t.Type\n\n    success: bool\n    _ndim: int\n\n    def __init__(\n        self,\n        res: _NDARRAY,\n        res_func: _t.Optional[_t.Callable] = None,\n        x: _t.Optional[_NDARRAY] = None,\n        data: _t.Optional[_NDARRAY] = None,\n        cov: _t.Optional[_NDARRAY] = None,\n        std: _t.Optional[_NDARRAY] = None,\n        stderr: _t.Optional[_NDARRAY] = None,\n        stdfunc: _t.Optional[_t.Callable] = None,\n        keys: _t.Optional[_t.Tuple[str, ...]] = None,\n        original_func: _t.Optional[_t.Callable] = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Initialize the FitResult class.\n        ---------------------------\n\n        Args:\n            res: Result value as NamedTuple.\n            res_func: Optional callable function for result.\n            x: Original x values used to fitted.\n            data: Original data that was fitted.\n            **kwargs: Additional keyword arguments that will be ignored.\n\n        Example to create yourself.\n        -----------------------------\n            &gt;&gt;&gt; result = ff.FitResult(res=(1, 2, 3), res_func=lambda x: x ** 2)\n\n        \"\"\"\n        del kwargs\n        self.res_array = np.asarray(res)\n        self._ndim = self.res_array.ndim\n        self.res_func = (\n            res_func if res_func is not None else (lambda x: np.ones_like(x) * np.nan)\n        )\n        self.x = x\n        self.data = data\n        self.cov = cov\n\n        if std is None:\n            if stderr is not None:\n                std = stderr\n            else:\n                std = np.ones_like(res) * np.nan\n        self._std_array = std\n\n        self.stderr = stderr if stderr is not None else np.zeros_like(res)\n        self.stdfunc = (\n            stdfunc if stdfunc is not None else (lambda x: np.ones_like(x) * np.nan)\n        )\n        self._res_dict = {}\n\n        self.success = bool(np.all(np.isnan(self.res_array)))\n\n        if keys is not None:\n            self.keys = keys\n        self._original_func = original_func\n\n        if not hasattr(self.__class__, \"param_class\"):\n\n            class RecreatedParamClass(FuncParamClass):\n                keys = self.keys\n\n            self.param_class = convert_param_class(RecreatedParamClass)\n\n    def get(self, parameter: _t.Union[str, int]) -&gt; _NDARRAY:\n        if isinstance(parameter, int):\n            return self.res_array[..., parameter]\n\n        if parameter not in self.keys:\n            raise ValueError(f\"Parameter {parameter} not found.\")\n        if parameter in self._res_dict:\n            return self._res_dict[parameter]\n        if self._ndim &gt; 1:\n            val = self.res_array[..., self.keys.index(parameter)]\n        else:\n            val = self.res_array[self.keys.index(parameter)]\n        self._res_dict[parameter] = val\n        return val\n\n    def get_result_at(self, index: int):\n        if self._ndim &gt; 1:\n            res = self.res_array[index]\n        else:\n            res = self.res_array\n\n        return self.__class__(\n            res,\n            lambda xx: self._original_func(xx, *res) if self._original_func else None,\n            x=self.x,\n            data=self.data,\n            cov=self.cov,\n            std=self._std_array,\n            stderr=self.stderr,\n            stdfunc=self.stdfunc,\n            keys=self.keys,\n            original_func=self._original_func,\n        )\n\n    def __getattr__(self, name: str) -&gt; _t.Any:\n        if name.startswith(\"_\"):\n            raise AttributeError(\n                f\"'{self.__class__.__name__}' object has no attribute '{name}'\"\n            )\n        return self.get(name)\n\n    def res_and_func(self) -&gt; _t.Tuple[_NDARRAY, _t.Callable]:\n        return self.res_array, self.res_func\n\n    @property\n    def res(self) -&gt; _T:\n        return self.param_class(*self.res_array.T)  # type: ignore\n\n    @property\n    def label(self) -&gt; _T:\n        return convert_to_label_instance(self.param_class, self.res_array)  # type: ignore\n\n    @property\n    def std(self) -&gt; _T:\n        return self.param_class(*self._std_array.T)  # type: ignore\n\n    def asdict(self) -&gt; _t.Dict[str, _NDARRAY]:\n        return {key: self.get(key) for key in self.keys}\n\n    def __repr__(self) -&gt; str:\n        return f\"{self.__class__.__name__}({self.keys})\"\n\n    def _repr_latex_(self) -&gt; str:\n        \"\"\"Return a LaTeX representation of the fit results for Jupyter notebooks.\n\n        Returns:\n            str: A LaTeX string representation of the fit results.\n        \"\"\"\n        if hasattr(self, \"__latex_repr__\"):\n            latex_repr = self.__latex_repr__\n\n            # latex_repr = latex_repr.format(**self.asdict())\n            for key, value in self.asdict().items():\n                value_str = format_value_to_latex(float(value))\n                latex_repr = latex_repr.replace(f\"&amp;{key}\", f\"{{{value_str}}}\")\n            return latex_repr\n\n        return self.__repr__()\n\n    def __iter__(self):\n        return iter(self.res_array)\n\n    def __call__(self, *args: _t.Any, **kwds: _t.Any) -&gt; _NDARRAY:\n        return self.res_func(*args, **kwds)\n\n    def __getitem__(self, index):\n        if isinstance(index, str):\n            return self.get(index)\n        if isinstance(index, int):\n            return self.res_array[..., index]\n        return self.res_array[index]\n\n    def plot(\n        self,\n        ax: _t.Optional[\"Axes\"] = None,\n        *,\n        x: _t.Optional[_t.Union[_NDARRAY, int]] = None,\n        label: _t.Optional[_t.Union[str, tuple, list]] = DEFAULT_FIT_LABEL,\n        color: _t.Optional[_t.Union[str, int]] = None,\n        title: _t.Optional[_t.Union[str, tuple, list]] = None,\n        post_func_x: _t.Optional[_t.Callable[[_NDARRAY], _NDARRAY]] = None,\n        post_func_y: _t.Optional[_t.Callable[[_NDARRAY], _NDARRAY]] = None,\n        **kwargs,\n    ):\n        \"\"\"Plot the fit results on the given axes.\n\n        Args:\n            ax (Optional[Axes]): The axes on which to plot the fit results. If None, a new axes will be created.\n            label (str): The label for the plot. Defaults to ffit.config.DEFAULT_FIT_LABEL.\n            color (Optional[Union[str, int]]): The color of the plot. If None, a default color will be used.\n            title (Optional[str]): The title for the plot. If provided, it will be appended to the existing title.\n            **kwargs: Additional keyword arguments to be passed to the plot function.\n\n        Returns:\n            FitResults: The FitResults object itself.\n\n        Example:\n            ```\n            &gt;&gt;&gt; result = ff.Cos().fit(x, y)\n            &gt;&gt;&gt; result.plot() # ax will be get from plt.gca()\n            &gt;&gt;&gt; result.plot(ax, x=x, label=\"Cosine fit\")\n            &gt;&gt;&gt; result.plot(ax, x=x, label=\"Cosine fit\", color=\"r\")\n            ```\n        Worth to mention: title will be appended to the existing title with a new line.\n\n\n        \"\"\"\n        ax = get_ax_from_gca(ax)\n        x_fit = get_right_x(x, ax, self.x)\n\n        y_fit = self.res_func(x_fit)\n        if label is not None:\n            # label = format_str_with_params(self.res, label)\n            if isinstance(label, (tuple, list)):\n                label = \"; \".join([str(ll) for ll in label])\n            label = str(label).strip()\n            kwargs.update({\"label\": label})\n\n        color = get_right_color(color)\n        kwargs.update({\"color\": color})\n\n        if post_func_x:\n            x_fit = post_func_x(x_fit)\n        if post_func_y:\n            y_fit = post_func_y(y_fit)\n        ax.plot(x_fit, y_fit, **kwargs)\n\n        if title:\n            # title = format_str_with_params(self.res, title)\n            if isinstance(title, (tuple, list)):\n                title = \"; \".join([str(t) for t in title])\n            current_title = ax.get_title()\n            if current_title:\n                title = f\"{current_title}\\n{title}\"\n            title = str(title).strip()\n            ax.set_title(title)\n\n        if label != DEFAULT_FIT_LABEL and label is not None:\n            ax.legend()\n\n        return self\n\n    def output_results(self, number_format: str = \".2e\") -&gt; str:\n        if np.all(self._std_array == 0):\n            return \"; \".join(\n                [\n                    f\"{key}: {self.res_array[i]:{number_format}}\"\n                    for i, key in enumerate(self.keys)\n                ]\n            )\n        return \"; \".join(\n            [\n                f\"{key}: {self.res_array[i]:{number_format}} \u00b1 {self._std_array[i]:{number_format}}\"\n                for i, key in enumerate(self.keys)\n            ]\n        )\n</code></pre>"},{"location":"fit_result/#ffit.fit_results.FitResult.plot","title":"plot","text":"<pre><code>plot(ax=None, *, x=None, label=DEFAULT_FIT_LABEL, color=None, title=None, post_func_x=None, post_func_y=None, **kwargs)\n</code></pre> <p>Plot the fit results on the given axes.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Optional[Axes]</code> <p>The axes on which to plot the fit results. If None, a new axes will be created.</p> <code>None</code> <code>label</code> <code>str</code> <p>The label for the plot. Defaults to ffit.config.DEFAULT_FIT_LABEL.</p> <code>DEFAULT_FIT_LABEL</code> <code>color</code> <code>Optional[Union[str, int]]</code> <p>The color of the plot. If None, a default color will be used.</p> <code>None</code> <code>title</code> <code>Optional[str]</code> <p>The title for the plot. If provided, it will be appended to the existing title.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to the plot function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResults</code> <p>The FitResults object itself.</p> Example <pre><code>&gt;&gt;&gt; result = ff.Cos().fit(x, y)\n&gt;&gt;&gt; result.plot() # ax will be get from plt.gca()\n&gt;&gt;&gt; result.plot(ax, x=x, label=\"Cosine fit\")\n&gt;&gt;&gt; result.plot(ax, x=x, label=\"Cosine fit\", color=\"r\")\n</code></pre> <p>Worth to mention: title will be appended to the existing title with a new line.</p> Source code in <code>ffit/fit_results.py</code> <pre><code>def plot(\n    self,\n    ax: _t.Optional[\"Axes\"] = None,\n    *,\n    x: _t.Optional[_t.Union[_NDARRAY, int]] = None,\n    label: _t.Optional[_t.Union[str, tuple, list]] = DEFAULT_FIT_LABEL,\n    color: _t.Optional[_t.Union[str, int]] = None,\n    title: _t.Optional[_t.Union[str, tuple, list]] = None,\n    post_func_x: _t.Optional[_t.Callable[[_NDARRAY], _NDARRAY]] = None,\n    post_func_y: _t.Optional[_t.Callable[[_NDARRAY], _NDARRAY]] = None,\n    **kwargs,\n):\n    \"\"\"Plot the fit results on the given axes.\n\n    Args:\n        ax (Optional[Axes]): The axes on which to plot the fit results. If None, a new axes will be created.\n        label (str): The label for the plot. Defaults to ffit.config.DEFAULT_FIT_LABEL.\n        color (Optional[Union[str, int]]): The color of the plot. If None, a default color will be used.\n        title (Optional[str]): The title for the plot. If provided, it will be appended to the existing title.\n        **kwargs: Additional keyword arguments to be passed to the plot function.\n\n    Returns:\n        FitResults: The FitResults object itself.\n\n    Example:\n        ```\n        &gt;&gt;&gt; result = ff.Cos().fit(x, y)\n        &gt;&gt;&gt; result.plot() # ax will be get from plt.gca()\n        &gt;&gt;&gt; result.plot(ax, x=x, label=\"Cosine fit\")\n        &gt;&gt;&gt; result.plot(ax, x=x, label=\"Cosine fit\", color=\"r\")\n        ```\n    Worth to mention: title will be appended to the existing title with a new line.\n\n\n    \"\"\"\n    ax = get_ax_from_gca(ax)\n    x_fit = get_right_x(x, ax, self.x)\n\n    y_fit = self.res_func(x_fit)\n    if label is not None:\n        # label = format_str_with_params(self.res, label)\n        if isinstance(label, (tuple, list)):\n            label = \"; \".join([str(ll) for ll in label])\n        label = str(label).strip()\n        kwargs.update({\"label\": label})\n\n    color = get_right_color(color)\n    kwargs.update({\"color\": color})\n\n    if post_func_x:\n        x_fit = post_func_x(x_fit)\n    if post_func_y:\n        y_fit = post_func_y(y_fit)\n    ax.plot(x_fit, y_fit, **kwargs)\n\n    if title:\n        # title = format_str_with_params(self.res, title)\n        if isinstance(title, (tuple, list)):\n            title = \"; \".join([str(t) for t in title])\n        current_title = ax.get_title()\n        if current_title:\n            title = f\"{current_title}\\n{title}\"\n        title = str(title).strip()\n        ax.set_title(title)\n\n    if label != DEFAULT_FIT_LABEL and label is not None:\n        ax.legend()\n\n    return self\n</code></pre>"},{"location":"develop/","title":"Developer Guidelines","text":"<p>It is not necessary to create a new class for every function, as the <code>ffit</code> package provides the <code>curve_fit</code> and <code>leastsq</code> methods. These methods return a <code>FitResult</code> object with similar functionality.</p> <p>However, if you want to create a new class for a function that offers additional features, you can follow the guidelines to create a custom class. This would allow you to later contribute this function to the package.</p>"},{"location":"develop/#contributing","title":"Contributing","text":"<p>To contribute to the package, you can create a pull request with your new function class. Ensure your contribution adheres to the provided guidelines and includes the necessary tests and documentation. Contributions are reviewed and merged as appropriate.</p>"},{"location":"develop/contribution/","title":"Contributing to the Project","text":"<p>We welcome contributions to this project and appreciate your interest in improving the library! Please follow these guidelines to ensure a smooth and productive collaboration.</p>"},{"location":"develop/contribution/#how-to-contribute","title":"How to Contribute","text":"<ul> <li> <p>Fork the Repository    Create a fork of the repository to your GitHub account.</p> </li> <li> <p>Clone Your Fork    Clone your fork to your local machine:</p> </li> </ul> <pre><code>git clone https://github.com/kyrylo-gr/ffit.git\ncd ffit\n</code></pre> <ul> <li>Create a Branch    Create a new branch for your feature or bugfix:</li> </ul> <pre><code>git checkout -b feature-or-bugfix-name\n</code></pre> <ul> <li>Install Dependencies    Set up the development environment by installing the required dependencies:</li> </ul> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"develop/contribution/#run-linters-and-formatters","title":"Run Linters and Formatters","text":"<p>Before submitting your changes, ensure your code follows the project's style and quality standards:</p> <ul> <li>Format code using Black:   <pre><code>black .\n</code></pre></li> <li>Lint code using Ruff:   <pre><code>ruff .\n</code></pre></li> <li>Additionally, run Flake8 with the following configuration:   <pre><code>flake8 . --count --max-complexity=10 --max-line-length=127 --ignore=E731,E741,E203,E265,E226,C901,W504,W503,E704\n</code></pre></li> </ul>"},{"location":"develop/contribution/#run-tests","title":"Run Tests","text":"<p>Ensure all tests pass:</p> <pre><code>pytest\n</code></pre>"},{"location":"develop/contribution/#create-documentation","title":"Create Documentation","text":"<p>The documentation is generated automatically from the docstrings in the code. It should be updated if any new functions are added. To update the documentation, follow these steps:</p> <pre><code>cd docs\npython create_functions_doc.py\n</code></pre>"},{"location":"develop/contribution/#submit-changes","title":"Submit Changes","text":"<ul> <li>Update the version   The version of the package should be increased by 0.0.1 for each new feature or bugfix. It's saved in the <code>ffit/__config__.py</code> file.</li> <li>Commit Changes    Commit your changes with a clear and concise message:</li> </ul> <pre><code>git commit -m \"Add feature/fix issue: description of the change\"\n</code></pre> <ul> <li>Push Changes    Push your branch to your fork:</li> </ul> <pre><code>git push origin feature-or-bugfix-name\n</code></pre> <ul> <li>Ensure your branch is up to date with the main branch:</li> </ul> <pre><code>git fetch upstream\ngit rebase upstream/main\n</code></pre> <ul> <li>Submit a Pull Request   Go to the original repository on GitHub and open a pull request. Provide a detailed description of the changes and reference any related issues.</li> </ul>"},{"location":"develop/contribution/#communication","title":"Communication","text":"<ul> <li>For questions, issues, or feedback, open a GitHub issue.</li> <li>Before opening a PR, it's can be helpful to discuss your changes in an issue first.</li> </ul> <p>Thank you for contributing! \ud83c\udf89</p>"},{"location":"develop/custom_class/","title":"Custom Function Class","text":""},{"location":"develop/custom_class/#custom-function-class","title":"Custom Function Class","text":"<p>This guide explains how to create a custom function class for use with the <code>ffit</code> package.</p> <p>To contribute a new class, create a new file in the <code>ffit/funcs</code> directory. Name it <code>custom_func.py</code> and include two classes: <code>CustomFuncParam</code> and <code>CustomFunc</code>.</p>"},{"location":"develop/custom_class/#create-a-param-class","title":"Create a Param Class","text":"<p>Start by defining the function parameters in a class that inherits from <code>ParamDataclass</code>.</p> <p>Also define the final result class that inherits from <code>FitResult</code> and <code>CustomFuncParam</code> to provide users with accurate typing. The final result class should have attribute <code>param_class</code> set to the converted <code>CustomFuncParam</code> class.</p> <pre><code>from dataclasses import dataclass\nfrom ffit.utils import FuncParamClass, convert_param_class\nfrom ffit.fit_results import FitResult\n\nclass CustomFuncParam(FuncParamClass):\n    \"\"\"CustomFunc function parameters.\n\n    Attributes\n    ----------\n    - attr1: float\n        First attribute of the function.\n    - attr2: float\n        Second attribute of the function.\n\n    Additional attributes\n    ----------------------\n    - param1: float\n        The param1 of the function.\n\n    Methods\n    -------\n    - meth1: float\n        The meth1 of the function.\n    \"\"\"\n    __slots__ = (\"attr1\", \"attr2\")\n    keys = (\"attr1\", \"attr2\")\n\n    @property\n    def param1(self):\n        return self.attr1 ** 2 # pylint: disable=E1101\n\n    def meth1(self):\n        return self.attr1 * self.attr2 # pylint: disable=E1101\n\nclass CustomFuncResult(CustomFuncParam, FitResult[CustomFuncParam]):\n    param_class = convert_param_class(CustomFuncParam)\n</code></pre>"},{"location":"develop/custom_class/#define-the-function","title":"Define the Function","text":"<p>Define the function to be used for fitting.</p> <p>The first argument is the x data (type <code>NDARRAY</code>), followed by the parameters in the same order as defined in <code>CustomFuncParam.keys</code>. The return type should be <code>NDARRAY</code>.</p> <pre><code>from ffit.utils import _NDARRAY\n\ndef custom_func(x: _NDARRAY, attr1: float, attr2: float) -&gt; _NDARRAY:\n    return attr1 * attr2\n</code></pre>"},{"location":"develop/custom_class/#define-the-guess-function","title":"Define the Guess Function","text":"<p>The guess function helps determine initial parameters.</p> <p>The first two arguments are the x and y data (type <code>NDARRAY</code>), followed by <code>**kwargs</code>. The return type should be <code>NDARRAY</code>.</p> <p>You can pass <code>kwargs</code> to the <code>fit</code> methods to improve guesses. For example, you might specify whether an exponential function is increasing or decreasing.</p> <pre><code>from ffit.utils import _NDARRAY\nimport numpy as np\n\ndef custom_func_guess(x: _NDARRAY, y: _NDARRAY, **kwargs) -&gt; _NDARRAY:\n    sign = kwargs.get(\"func_sign\", np.sign(np.mean(y)))\n    return np.array([...])\n</code></pre>"},{"location":"develop/custom_class/#normalize-the-result","title":"Normalize the Result","text":"<p>Normalize results to avoid stochastic behavior in the fit function.</p> <p>For example, ensure phases are \\(2\\pi\\) periodic or set one parameter to always be positive.</p> <pre><code>from typing import Sequence\nimport numpy as np\n\ndef normalize_res_list(x: Sequence[float]) -&gt; _NDARRAY:\n    return np.array([\n        abs(x[0]),\n        np.sign(x[0]) * x[1],\n        x[2] % (2 * np.pi),\n        x[3]\n    ])\n</code></pre>"},{"location":"develop/custom_class/#define-the-class","title":"Define the Class","text":"<p>The main class should inherit from <code>FitLogic[CustomFuncResult]</code>. Set <code>CustomFuncResult</code> correctly to provide users with accurate typing.</p> <p>Include a minimalistic docstring with LaTeX and Python representations of the function, as well as a reference to the final parameters class.</p> <pre><code>from ffit.fit_logic import FitLogic\nimport typing as _t\n\nclass CustomFunc(FitLogic[CustomFuncResult]): # type: ignore\n    r\"\"\"CustomFunc function.\n    ---\n\n    $$\n    f(x)^2 = \\cos(\\omega)\n    $$\n\n        f(x) = sqrt(cos(2 * pi * frequency))\n\n    Final Parameters\n    -----------------\n    The final parameters are given by [`CustomFuncParam`](../custom_func_param/) dataclass.\n    \"\"\"\n    _result_class: _t.Type[CustomFuncResult] = CustomFuncResult\n\n    func = staticmethod(custom_func)\n    normalize_res = staticmethod(normalize_res_list)\n    _guess = staticmethod(custom_func_guess)\n</code></pre>"},{"location":"develop/custom_class/#additional-information","title":"Additional Information","text":"<p>In order to submit a new function, each function class should include the following information.</p>"},{"location":"develop/custom_class/#example-parameters","title":"Example Parameters","text":"<p>Provide example parameters for documentation plots:</p> <pre><code>    _example_param = (1, 1, 1.0, 1.0)\n    # Additionally you can setup the x axis:\n    _example_x_min: float\n    _example_x_max: float\n    _example_x_points: int\n    _example_std: float\n</code></pre>"},{"location":"develop/custom_class/#mask-signature","title":"Mask Signature","text":"<p>Add a mask method signature for better autocompletion.</p> <p>Ensure the attributes match those in <code>CustomFuncParam</code>.</p> <pre><code>    @overload\n    @classmethod\n    def mask(  # type: ignore # pylint: disable=W0221\n        cls,\n        *,\n        attr1: float = None, # type: ignore\n        attr2: float = None, # type: ignore\n    ) -&gt; \"CustomFunc\": ...\n\n    @classmethod\n    def mask(cls, **kwargs) -&gt; \"CustomFunc\":\n        return super().mask(**kwargs)\n</code></pre>"},{"location":"develop/custom_class/#testing-range","title":"Testing Range","text":"<p>Specify attribute testing ranges to ensure proper function behavior.</p> <p>If not set, the default range is (-100, 100).</p> <pre><code>    _test_range = {\n        \"attr1\": (0, 1),\n        \"attr2\": None,\n    }\n</code></pre>"},{"location":"functions/","title":"Implemented functions","text":"<p>Here is a list of the all implemented functions sorted alphabetically.</p>"},{"location":"functions/#complexspiral","title":"ComplexSpiral","text":""},{"location":"functions/#cos","title":"Cos","text":""},{"location":"functions/#exp","title":"Exp","text":""},{"location":"functions/#expdecayingcos","title":"ExpDecayingCos","text":""},{"location":"functions/#gaussian","title":"Gaussian","text":""},{"location":"functions/#hyperbola","title":"Hyperbola","text":""},{"location":"functions/#line","title":"Line","text":""},{"location":"functions/#log","title":"Log","text":""},{"location":"functions/#lorentzian","title":"Lorentzian","text":""},{"location":"functions/complex_spiral/","title":"ComplexSpiral","text":""},{"location":"functions/complex_spiral/#simples-example","title":"Simples example","text":"<pre><code>&gt;&gt;&gt; from ffit.funcs.complex_spiral import ComplexSpiral\n\n# Call the fit method with x and y data.\n&gt;&gt;&gt; fit_result = ComplexSpiral().fit(x, y)\n\n# The result is a FitResult object that can be unpacked.\n&gt;&gt;&gt; res, res_func = fit_result.res_and_func()\n\n# The parameters can be accessed as attributes.\n&gt;&gt; amplitude0 = fit_result.amplitude0\n\n# One can combine multiple calls in one line.\n&gt;&gt;&gt; res = ComplexSpiral().fit(x, y, guess=[1, 2, 3, 4]).plot(ax)\n</code></pre>"},{"location":"functions/complex_spiral/#final-parameters","title":"Final parameters","text":"<p>Complex spiral parameters.</p> <p>Attributes:</p> Name Type Description <code>amplitude0</code> <code>float</code> <p>The absolute amplitude of the spiral.</p> <code>frequency</code> <code>float</code> <p>The frequency of the spiral.</p> <code>phi0</code> <code>float</code> <p>The phase of the spiral.</p> <code>tau</code> <code>float</code> <p>The time constant of the spiral.</p> <code>offset_amp</code> <code>float</code> <p>The amplitude offset of the spiral.</p> <code>offset_phase</code> <code>float</code> <p>The phase offset of the spiral.</p> <p>More attributes:</p> <ul> <li>offset (complex):         Calculates the complex offset based on the amplitude and phase offsets.</li> <li>amplitude (complex):         Calculates the complex amplitude based on the initial amplitude and phase.</li> <li>rate (float):         Calculates the rate of decay of the spiral.</li> <li>omega (float):         Calculates the angular frequency of the spiral.</li> </ul> Source code in <code>ffit/funcs/complex_spiral.py</code> <pre><code>class ComplexSpiralParam(_t.Generic[_T], FuncParamClass):\n    \"\"\"Complex spiral parameters.\n\n    Attributes:\n        amplitude0 (float):\n            The absolute amplitude of the spiral.\n        frequency (float):\n            The frequency of the spiral.\n        phi0 (float):\n            The phase of the spiral.\n        tau (float):\n            The time constant of the spiral.\n        offset_amp (float):\n            The amplitude offset of the spiral.\n        offset_phase (float):\n            The phase offset of the spiral.\n\n    More attributes:\n\n    - offset (complex):\n            Calculates the complex offset based on the amplitude and phase offsets.\n    - amplitude (complex):\n            Calculates the complex amplitude based on the initial amplitude and phase.\n    - rate (float):\n            Calculates the rate of decay of the spiral.\n    - omega (float):\n            Calculates the angular frequency of the spiral.\n    \"\"\"\n\n    keys = (\n        \"amplitude0\",\n        \"frequency\",\n        \"phi0\",\n        \"tau\",\n        \"offset_amp\",\n        \"offset_phase\",\n    )\n\n    amplitude0: _T\n    frequency: _T\n    phi0: _T\n    tau: _T\n    offset_amp: _T\n    offset_phase: _T\n\n    __latex_repr__ = (\n        r\"$&amp;amplitude0 \\cdot e^{i \\cdot &amp;phi0} \\cdot \"\n        r\"e^{i \\cdot 2\\pi \\cdot &amp;frequency \\cdot x - x/&amp;tau} + \"\n        r\"e^{i \\cdot &amp;offset_phase} \\cdot &amp;offset_amp$\"\n    )\n    __latex_repr_symbols__ = {\n        \"amplitude0\": r\"Z_0\",\n        \"frequency\": r\"f\",\n        \"phi0\": r\"\\phi_0\",\n        \"tau\": r\"\\tau\",\n        \"offset_amp\": r\"Z_{\\text{offset}}\",\n        \"offset_phase\": r\"\\phi_{\\text{offset}}\",\n    }\n\n    @property\n    def offset(self) -&gt; _T:\n        return self.offset_amp * np.exp(1j * self.offset_phase)  # type: ignore\n\n    @property\n    def amplitude(self) -&gt; _T:\n        return self.amplitude0 * np.exp(1j * self.phi0)  # type: ignore\n\n    @property\n    def rate(self) -&gt; _T:\n        return -1.0 / self.tau  # type: ignore\n\n    @property\n    def omega(self) -&gt; _T:\n        return 2 * np.pi * self.frequency  # type: ignore\n</code></pre>"},{"location":"functions/complex_spiral/#ffit.funcs.complex_spiral.ComplexSpiral--complex-spiral-function","title":"Complex Spiral function.","text":"<p>By default, the function has exponential decay:</p> \\[ f(x) = Z_0 * \\exp(i\u22c5\u03c9\u22c5x) \\exp(-x/\u03c4) + Z_{\\text{offset}} \\] <pre><code>f(x) = (\n    amplitude0 * np.exp(1j * phi0)\n    * np.exp(1j * 2 * np.pi * frequency * x - x / tau)\n    + np.exp(1j * offset_phase) * offset_amp\n)\n</code></pre>"},{"location":"functions/complex_spiral/#ffit.funcs.complex_spiral.ComplexSpiral--alternative-functions","title":"Alternative functions","text":"<p><code>ComplexSpiral.GaussianDecay</code>:</p> \\[     f(x) = Z_0 \\exp(i\u22c5\u03c9\u22c5x) \\exp(-x^2/\u03c4^2) + Z_{\\text{offset}} \\] <pre><code>f(x) = (\n    amplitude0 * np.exp(1j * phi0)\n    * np.exp(1j * frequency * 2 * np.pi * x - x**2 / tau**2)\n    + np.exp(1j * offset_phase) * offset_amp\n</code></pre>"},{"location":"functions/complex_spiral/#ffit.funcs.complex_spiral.ComplexSpiral--final-parameters","title":"Final parameters","text":"<p>The final parameters are given by <code>ComplexSpiralParam</code> dataclass.</p> Source code in <code>ffit/funcs/complex_spiral.py</code> <pre><code>class ComplexSpiral(ComplexSpiralExpDecay):\n    r\"\"\"Complex Spiral function.\n    --------\n    By default, the function has exponential decay:\n\n    $$\n    f(x) = Z_0 * \\exp(i\u22c5\u03c9\u22c5x) \\exp(-x/\u03c4) + Z_{\\text{offset}}\n    $$\n\n        f(x) = (\n            amplitude0 * np.exp(1j * phi0)\n            * np.exp(1j * 2 * np.pi * frequency * x - x / tau)\n            + np.exp(1j * offset_phase) * offset_amp\n        )\n\n    Alternative functions\n    ----------------------\n\n    `ComplexSpiral.GaussianDecay`:\n\n    $$\n        f(x) = Z_0 \\exp(i\u22c5\u03c9\u22c5x) \\exp(-x^2/\u03c4^2) + Z_{\\text{offset}}\n    $$\n\n        f(x) = (\n            amplitude0 * np.exp(1j * phi0)\n            * np.exp(1j * frequency * 2 * np.pi * x - x**2 / tau**2)\n            + np.exp(1j * offset_phase) * offset_amp\n\n\n    Final parameters\n    -----------------\n    The final parameters are given by [`ComplexSpiralParam`](../complex_spiral_param/) dataclass.\n    \"\"\"\n\n    GaussianDecay = ComplexSpiralGaussianDecay\n    ExpDecay = ComplexSpiralExpDecay\n    _doc_ignore = False\n</code></pre>"},{"location":"functions/complex_spiral/#ffit.funcs.complex_spiral.ComplexSpiral.fit","title":"fit","text":"<pre><code>fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n    if len(x) != len(data):\n        raise ValueError(\"x and data must have the same length\")\n    if mask is not None and len(mask) != len(x):\n        raise ValueError(\"mask must have the same length as x and data\")\n\n    res, res_std = self._fit(\n        x,\n        data,\n        mask=mask,\n        guess=guess,\n        method=method,\n        maxfev=maxfev,\n        **kwargs,\n    )\n\n    # param = self.param(*res, std=res_std)\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    # print(res)\n    return self._result_class(\n        res,\n        lambda x: full_func(x, *res),\n        std=res_std,\n        x=x,\n        data=data,\n        stderr=res_std,\n        stdfunc=lambda x: self.get_func_std()(x, *res, *res_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/complex_spiral/#ffit.funcs.complex_spiral.ComplexSpiral.async_fit","title":"async_fit  <code>async</code>","text":"<pre><code>async_fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Asynchronously fits the model to the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable data.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable data to fit.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>An optional mask to apply to the data. Defaults to None.</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>An optional initial guess for the fitting parameters. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the fitting function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>_T</code> <p>FitWithErrorResult[_T]: The result of the fitting process, including the fitted parameters and associated errors.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>async def async_fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"\n    Asynchronously fits the model to the provided data.\n\n    Args:\n        x (_ARRAY): The independent variable data.\n        data (_ARRAY): The dependent variable data to fit.\n        mask (Optional[Union[_ARRAY, float]], optional): An optional mask to apply to the data. Defaults to None.\n        guess (Optional[_T], optional): An optional initial guess for the fitting parameters. Defaults to None.\n        **kwargs: Additional keyword arguments to pass to the fitting function.\n\n    Returns:\n        FitWithErrorResult[_T]:\n            The result of the fitting process, including the fitted parameters and associated errors.\n    \"\"\"\n    return self.fit(\n        x, data, mask=mask, guess=guess, method=method, maxfev=maxfev, **kwargs\n    )\n</code></pre>"},{"location":"functions/complex_spiral/#ffit.funcs.complex_spiral.ComplexSpiral.guess","title":"guess  <code>classmethod</code>","text":"<pre><code>guess(x, data, mask=None, guess=None, **kwargs)\n</code></pre> <p>Guess the initial fit parameters.</p> <p>This function returns an object of the class <code>FitResult</code>. See its documentation for more information on what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>The independent variable.</p> required <code>data</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>The initial guess for the fit parameters (optional).</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The guess, including the guess parameters and the function based on the guess.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n&gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n&gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n&gt;&gt;&gt; fit_guess.plot()\n</code></pre> Source code in <code>ffit/fit_logic.py</code> <pre><code>@classmethod\ndef guess(\n    cls,\n    x,\n    data,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Guess the initial fit parameters.\n\n    This function returns an object of the class `FitResult`.\n    See its documentation for more information on what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for the fit parameters (optional).\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The guess, including the guess parameters and the function based on the guess.\n\n    Examples:\n        &gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n        &gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n        &gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n        &gt;&gt;&gt; fit_guess.plot()\n    \"\"\"\n    if guess is not None:\n        return cls._result_class(\n            np.asarray(guess),\n            lambda x: cls.func(x, *guess),\n            x=x,\n            data=data,\n        )\n    x_masked, data_masked = get_masked_data(x, data, mask, mask_min_len=1)\n    guess_param = cls._guess(x_masked, data_masked, **kwargs)\n    return cls._result_class(\n        np.asarray(guess_param),\n        lambda x: cls.func(x, *guess_param),\n        x=x,\n        data=data,\n    )\n</code></pre>"},{"location":"functions/complex_spiral/#ffit.funcs.complex_spiral.ComplexSpiral.bootstrapping","title":"bootstrapping","text":"<pre><code>bootstrapping(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, maxfev=_DEFAULT_MAXFEV, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, _ANY_LIST_LIKE]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>The number of permutations to use for the bootstrapping.</p> <code>None</code> <code>maxfev</code> <code>int</code> <p>The maximum number of function evaluations.</p> <code>_DEFAULT_MAXFEV</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, _ANY_LIST_LIKE]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    maxfev: int = _DEFAULT_MAXFEV,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        num_of_permutations: The number of permutations to use for the bootstrapping.\n        maxfev: The maximum number of function evaluations.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    res_means, total_std = self._bootstrapping(\n        x, data, mask, guess, method, num_of_permutations, maxfev\n    )\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/complex_spiral/#ffit.funcs.complex_spiral.ComplexSpiral.array_bootstrapping","title":"array_bootstrapping","text":"<pre><code>array_bootstrapping(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, num_of_permutations=None, **kwargs)\n</code></pre> <p>Perform array bootstrapping in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>Number of bootstrap iterations.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the bootstrapping.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def array_bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array bootstrapping in parallel.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        num_of_permutations: Number of bootstrap iterations.\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the bootstrapping.\n    \"\"\"\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Run bootstrapping on each dataset\n    results = np.array(\n        [\n            self._bootstrapping(\n                x[i] if multi_x else x,\n                data[i],\n                mask=mask,\n                guess=guess,\n                method=method,\n                num_of_permutations=num_of_permutations,\n                maxfev=maxfev,\n                **kwargs,\n            )\n            for i in range(len(data))\n        ]\n    )\n\n    # Split means and stds from results\n    result_means = results[:, 0, :]  # First element of each result is means\n    result_stds = results[:, 1, :]  # Second element is standard deviations\n\n    # Reshape results back to original data shape\n    result_means = result_means.reshape(data_shape[:-1] + (-1,))\n    result_stds = result_stds.reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        result_means,\n        self._create_array_res_func(\n            result_means, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        stderr=result_stds,\n        stdfunc=lambda x: self.get_func_std()(x, *result_means, *result_stds),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/complex_spiral/#ffit.funcs.complex_spiral.ComplexSpiral.bootstrapping2D","title":"bootstrapping2D","text":"<pre><code>bootstrapping2D(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The 2D dependent variable (data, batches).</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping2D(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The 2D dependent variable (data, batches).\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    # Mask the data and check that length of masked data is greater than lens of params\n    x_masked, data_masked = get_masked_data(x, data, mask, self._param_len)\n    if len(x_masked) == 0 or len(data_masked) == 0:\n        return self._result_class(\n            np.ones(self._param_len) * np.nan,\n            x=x,\n            data=data,\n        )\n\n    # Get a guess if not provided\n    if guess is None:\n        guess = self._guess(x_masked, np.mean(data_masked, axis=-1), **kwargs)\n\n    # Fit ones to get the best initial guess\n    guess, cov = self._run_fit(\n        x_masked, np.mean(data_masked, axis=-1), guess, method\n    )\n\n    # Run fit on random subarrays\n    all_res = []\n    total_elements = data_masked.shape[1]\n    if num_of_permutations is None:\n        num_of_permutations = int(min(max(total_elements / 10, 1_000), 5_000))\n\n    for selected_index in bootstrap_generator(total_elements, num_of_permutations):\n        res, _ = self._run_fit(\n            x_masked,\n            np.mean(data_masked[:, selected_index], axis=-1),\n            guess,\n            method,\n        )\n        if self.normalize_res is not None:  # type: ignore\n            res = self.normalize_res(res)  # type: ignore\n        all_res.append(res)\n\n    res_means = np.mean(all_res, axis=0)\n    bootstrap_std = np.std(all_res, axis=0)\n    total_std = bootstrap_std\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        cov=cov,  # type: ignore\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/complex_spiral/#ffit.funcs.complex_spiral.ComplexSpiral.mp_array_fit","title":"mp_array_fit","text":"<pre><code>mp_array_fit(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, n_jobs=None, **kwargs)\n</code></pre> <p>Perform array fitting in parallel using multiprocessing.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>n_jobs</code> <code>Optional[int]</code> <p>Number of processes to use. If None, uses cpu_count().</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def mp_array_fit(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_t.Union[_ARRAY, float]] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    n_jobs: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array fitting in parallel using multiprocessing.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        n_jobs: Number of processes to use. If None, uses cpu_count().\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the fit.\n    \"\"\"\n    import multiprocessing as mp\n\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Prepare arguments for parallel processing\n    fit_args = [\n        (x[i] if multi_x else x, data[i], mask, guess, method, maxfev, kwargs)\n        for i in range(len(data))\n    ]\n\n    # Run fits in parallel using multiprocessing\n    with mp.Pool(processes=n_jobs) as pool:\n        results = pool.map(self._fit_worker, fit_args)\n\n    results = np.array(results).reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        results,\n        self._create_array_res_func(\n            results, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/cos/","title":"Cos","text":""},{"location":"functions/cos/#simples-example","title":"Simples example","text":"<pre><code>&gt;&gt;&gt; from ffit.funcs.cos import Cos\n\n# Call the fit method with x and y data.\n&gt;&gt;&gt; fit_result = Cos().fit(x, y)\n\n# The result is a FitResult object that can be unpacked.\n&gt;&gt;&gt; res, res_func = fit_result.res_and_func()\n\n# The parameters can be accessed as attributes.\n&gt;&gt; amplitude = fit_result.amplitude\n\n# One can combine multiple calls in one line.\n&gt;&gt;&gt; res = Cos().fit(x, y, guess=[1, 2, 3, 4]).plot(ax)\n</code></pre>"},{"location":"functions/cos/#final-parameters","title":"Final parameters","text":"<p>Cos function parameters.</p> <pre><code>amplitude (float):\n    The amplitude.\nfrequency (float):\n    The frequency in 1/[x] units.\nphi0 (float):\n    The phase inside cos.\noffset (float):\n    The global offset.\n</code></pre>"},{"location":"functions/cos/#ffit.funcs.cos.CosParam--additional-attributes","title":"Additional attributes:","text":"<pre><code>omega (float):\n    The angular frequency.\n</code></pre> Source code in <code>ffit/funcs/cos.py</code> <pre><code>class CosParam(_t.Generic[_T], FuncParamClass):\n    \"\"\"Cos function parameters.\n\n    Attributes:\n    -----------------\n        amplitude (float):\n            The amplitude.\n        frequency (float):\n            The frequency in 1/[x] units.\n        phi0 (float):\n            The phase inside cos.\n        offset (float):\n            The global offset.\n\n    Additional attributes:\n    -----------------\n        omega (float):\n            The angular frequency.\n\n    \"\"\"\n\n    # __slots__ = (\"amplitude\", \"frequency\", \"phi0\", \"offset\")\n    keys = (\"amplitude\", \"frequency\", \"phi0\", \"offset\")\n    amplitude: _T\n    frequency: _T\n    phi0: _T\n    offset: _T\n\n    __latex_repr__ = (\n        r\"$&amp;amplitude \\cdot \\cos(2\\pi \\cdot &amp;frequency \\cdot x + &amp;phi0) + &amp;offset$\"\n    )\n    __latex_repr_symbols__ = {\n        \"amplitude\": r\"A\",\n        \"frequency\": r\"f\",\n        \"phi0\": r\"\\phi_0\",\n        \"offset\": r\"b\",\n    }\n\n    @property\n    def omega(self) -&gt; _T:\n        return 2 * np.pi * self.frequency  # pylint: disable=E1101  # type: ignore\n</code></pre>"},{"location":"functions/cos/#ffit.funcs.cos.Cos--cosine-function","title":"Cosine function.","text":"\\[ f(x) = A * \\cos(\u03c9 \u22c5 x + \\phi_0) + A_0 \\] <pre><code>f(x) = amplitude * cos(2 * pi * frequency * x + phi0) + offset\n</code></pre>"},{"location":"functions/cos/#ffit.funcs.cos.Cos--final-parameters","title":"Final parameters","text":"<p>The final parameters are given by <code>CosParam</code> dataclass.</p> Source code in <code>ffit/funcs/cos.py</code> <pre><code>class Cos(FitLogic[CosResult]):  # type: ignore\n    r\"\"\"Cosine function.\n    --------\n\n    $$\n    f(x) = A * \\cos(\u03c9 \u22c5 x + \\phi_0) + A_0\n    $$\n\n        f(x) = amplitude * cos(2 * pi * frequency * x + phi0) + offset\n\n    Final parameters\n    -----------------\n    The final parameters are given by [`CosParam`](../cos_param/) dataclass.\n    \"\"\"\n\n    _result_class: _t.Type[CosResult] = CosResult\n\n    func = staticmethod(cos_func)\n    # func_std = staticmethod(cos_error)\n\n    normalize_res = staticmethod(normalize_res_list)\n    _guess = staticmethod(cos_guess)\n\n    _example_param = (1, 1, 1.0, 1.0)\n\n    @_t.overload\n    @classmethod\n    def mask(  # type: ignore # pylint: disable=W0221\n        cls,\n        *,\n        amplitude: float = None,  # type: ignore\n        frequency: float = None,  # type: ignore\n        phi0: float = None,  # type: ignore\n        offset: float = None,  # type: ignore\n    ) -&gt; \"Cos\": ...\n\n    @classmethod\n    def mask(cls, **kwargs) -&gt; \"Cos\":\n        return super().mask(**kwargs)\n</code></pre>"},{"location":"functions/cos/#ffit.funcs.cos.Cos.fit","title":"fit","text":"<pre><code>fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n    if len(x) != len(data):\n        raise ValueError(\"x and data must have the same length\")\n    if mask is not None and len(mask) != len(x):\n        raise ValueError(\"mask must have the same length as x and data\")\n\n    res, res_std = self._fit(\n        x,\n        data,\n        mask=mask,\n        guess=guess,\n        method=method,\n        maxfev=maxfev,\n        **kwargs,\n    )\n\n    # param = self.param(*res, std=res_std)\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    # print(res)\n    return self._result_class(\n        res,\n        lambda x: full_func(x, *res),\n        std=res_std,\n        x=x,\n        data=data,\n        stderr=res_std,\n        stdfunc=lambda x: self.get_func_std()(x, *res, *res_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/cos/#ffit.funcs.cos.Cos.async_fit","title":"async_fit  <code>async</code>","text":"<pre><code>async_fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Asynchronously fits the model to the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable data.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable data to fit.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>An optional mask to apply to the data. Defaults to None.</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>An optional initial guess for the fitting parameters. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the fitting function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>_T</code> <p>FitWithErrorResult[_T]: The result of the fitting process, including the fitted parameters and associated errors.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>async def async_fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"\n    Asynchronously fits the model to the provided data.\n\n    Args:\n        x (_ARRAY): The independent variable data.\n        data (_ARRAY): The dependent variable data to fit.\n        mask (Optional[Union[_ARRAY, float]], optional): An optional mask to apply to the data. Defaults to None.\n        guess (Optional[_T], optional): An optional initial guess for the fitting parameters. Defaults to None.\n        **kwargs: Additional keyword arguments to pass to the fitting function.\n\n    Returns:\n        FitWithErrorResult[_T]:\n            The result of the fitting process, including the fitted parameters and associated errors.\n    \"\"\"\n    return self.fit(\n        x, data, mask=mask, guess=guess, method=method, maxfev=maxfev, **kwargs\n    )\n</code></pre>"},{"location":"functions/cos/#ffit.funcs.cos.Cos.guess","title":"guess  <code>classmethod</code>","text":"<pre><code>guess(x, data, mask=None, guess=None, **kwargs)\n</code></pre> <p>Guess the initial fit parameters.</p> <p>This function returns an object of the class <code>FitResult</code>. See its documentation for more information on what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>The independent variable.</p> required <code>data</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>The initial guess for the fit parameters (optional).</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The guess, including the guess parameters and the function based on the guess.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n&gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n&gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n&gt;&gt;&gt; fit_guess.plot()\n</code></pre> Source code in <code>ffit/fit_logic.py</code> <pre><code>@classmethod\ndef guess(\n    cls,\n    x,\n    data,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Guess the initial fit parameters.\n\n    This function returns an object of the class `FitResult`.\n    See its documentation for more information on what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for the fit parameters (optional).\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The guess, including the guess parameters and the function based on the guess.\n\n    Examples:\n        &gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n        &gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n        &gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n        &gt;&gt;&gt; fit_guess.plot()\n    \"\"\"\n    if guess is not None:\n        return cls._result_class(\n            np.asarray(guess),\n            lambda x: cls.func(x, *guess),\n            x=x,\n            data=data,\n        )\n    x_masked, data_masked = get_masked_data(x, data, mask, mask_min_len=1)\n    guess_param = cls._guess(x_masked, data_masked, **kwargs)\n    return cls._result_class(\n        np.asarray(guess_param),\n        lambda x: cls.func(x, *guess_param),\n        x=x,\n        data=data,\n    )\n</code></pre>"},{"location":"functions/cos/#ffit.funcs.cos.Cos.bootstrapping","title":"bootstrapping","text":"<pre><code>bootstrapping(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, maxfev=_DEFAULT_MAXFEV, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, _ANY_LIST_LIKE]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>The number of permutations to use for the bootstrapping.</p> <code>None</code> <code>maxfev</code> <code>int</code> <p>The maximum number of function evaluations.</p> <code>_DEFAULT_MAXFEV</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, _ANY_LIST_LIKE]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    maxfev: int = _DEFAULT_MAXFEV,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        num_of_permutations: The number of permutations to use for the bootstrapping.\n        maxfev: The maximum number of function evaluations.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    res_means, total_std = self._bootstrapping(\n        x, data, mask, guess, method, num_of_permutations, maxfev\n    )\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/cos/#ffit.funcs.cos.Cos.array_bootstrapping","title":"array_bootstrapping","text":"<pre><code>array_bootstrapping(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, num_of_permutations=None, **kwargs)\n</code></pre> <p>Perform array bootstrapping in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>Number of bootstrap iterations.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the bootstrapping.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def array_bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array bootstrapping in parallel.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        num_of_permutations: Number of bootstrap iterations.\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the bootstrapping.\n    \"\"\"\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Run bootstrapping on each dataset\n    results = np.array(\n        [\n            self._bootstrapping(\n                x[i] if multi_x else x,\n                data[i],\n                mask=mask,\n                guess=guess,\n                method=method,\n                num_of_permutations=num_of_permutations,\n                maxfev=maxfev,\n                **kwargs,\n            )\n            for i in range(len(data))\n        ]\n    )\n\n    # Split means and stds from results\n    result_means = results[:, 0, :]  # First element of each result is means\n    result_stds = results[:, 1, :]  # Second element is standard deviations\n\n    # Reshape results back to original data shape\n    result_means = result_means.reshape(data_shape[:-1] + (-1,))\n    result_stds = result_stds.reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        result_means,\n        self._create_array_res_func(\n            result_means, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        stderr=result_stds,\n        stdfunc=lambda x: self.get_func_std()(x, *result_means, *result_stds),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/cos/#ffit.funcs.cos.Cos.bootstrapping2D","title":"bootstrapping2D","text":"<pre><code>bootstrapping2D(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The 2D dependent variable (data, batches).</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping2D(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The 2D dependent variable (data, batches).\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    # Mask the data and check that length of masked data is greater than lens of params\n    x_masked, data_masked = get_masked_data(x, data, mask, self._param_len)\n    if len(x_masked) == 0 or len(data_masked) == 0:\n        return self._result_class(\n            np.ones(self._param_len) * np.nan,\n            x=x,\n            data=data,\n        )\n\n    # Get a guess if not provided\n    if guess is None:\n        guess = self._guess(x_masked, np.mean(data_masked, axis=-1), **kwargs)\n\n    # Fit ones to get the best initial guess\n    guess, cov = self._run_fit(\n        x_masked, np.mean(data_masked, axis=-1), guess, method\n    )\n\n    # Run fit on random subarrays\n    all_res = []\n    total_elements = data_masked.shape[1]\n    if num_of_permutations is None:\n        num_of_permutations = int(min(max(total_elements / 10, 1_000), 5_000))\n\n    for selected_index in bootstrap_generator(total_elements, num_of_permutations):\n        res, _ = self._run_fit(\n            x_masked,\n            np.mean(data_masked[:, selected_index], axis=-1),\n            guess,\n            method,\n        )\n        if self.normalize_res is not None:  # type: ignore\n            res = self.normalize_res(res)  # type: ignore\n        all_res.append(res)\n\n    res_means = np.mean(all_res, axis=0)\n    bootstrap_std = np.std(all_res, axis=0)\n    total_std = bootstrap_std\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        cov=cov,  # type: ignore\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/cos/#ffit.funcs.cos.Cos.mp_array_fit","title":"mp_array_fit","text":"<pre><code>mp_array_fit(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, n_jobs=None, **kwargs)\n</code></pre> <p>Perform array fitting in parallel using multiprocessing.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>n_jobs</code> <code>Optional[int]</code> <p>Number of processes to use. If None, uses cpu_count().</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def mp_array_fit(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_t.Union[_ARRAY, float]] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    n_jobs: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array fitting in parallel using multiprocessing.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        n_jobs: Number of processes to use. If None, uses cpu_count().\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the fit.\n    \"\"\"\n    import multiprocessing as mp\n\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Prepare arguments for parallel processing\n    fit_args = [\n        (x[i] if multi_x else x, data[i], mask, guess, method, maxfev, kwargs)\n        for i in range(len(data))\n    ]\n\n    # Run fits in parallel using multiprocessing\n    with mp.Pool(processes=n_jobs) as pool:\n        results = pool.map(self._fit_worker, fit_args)\n\n    results = np.array(results).reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        results,\n        self._create_array_res_func(\n            results, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/exp/","title":"Exp","text":""},{"location":"functions/exp/#simples-example","title":"Simples example","text":"<pre><code>&gt;&gt;&gt; from ffit.funcs.exp import Exp\n\n# Call the fit method with x and y data.\n&gt;&gt;&gt; fit_result = Exp().fit(x, y)\n\n# The result is a FitResult object that can be unpacked.\n&gt;&gt;&gt; res, res_func = fit_result.res_and_func()\n\n# The parameters can be accessed as attributes.\n&gt;&gt; amplitude = fit_result.amplitude\n\n# One can combine multiple calls in one line.\n&gt;&gt;&gt; res = Exp().fit(x, y, guess=[1, 2, 3, 4]).plot(ax)\n</code></pre>"},{"location":"functions/exp/#final-parameters","title":"Final parameters","text":"<p>Exponential function parameters.</p> <p>Attributes:</p> Name Type Description <code>amplitude</code> <code>float</code> <p>The amplitude of the exponential function.</p> <code>rate</code> <code>float</code> <p>The rate of the exponential function.</p> <code>offset</code> <code>float</code> <p>The offset of the exponential function.</p> Additional attributes <p>tau (float):     The time constant of the exponential function, calculated as -1 / rate.</p> Source code in <code>ffit/funcs/exp.py</code> <pre><code>class ExpParam(_t.Generic[_T], FuncParamClass):\n    \"\"\"Exponential function parameters.\n\n    Attributes:\n        amplitude (float):\n            The amplitude of the exponential function.\n        rate (float):\n            The rate of the exponential function.\n        offset (float):\n            The offset of the exponential function.\n\n    Additional attributes:\n        tau (float):\n            The time constant of the exponential function, calculated as -1 / rate.\n    \"\"\"\n\n    keys = (\"amplitude\", \"rate\", \"offset\")\n\n    amplitude: _T\n    rate: _T\n    offset: _T\n\n    __latex_repr__ = r\"$&amp;amplitude \\cdot \\exp(&amp;rate \\cdot x) + &amp;offset$\"\n    __latex_repr_symbols__ = {\n        \"amplitude\": r\"A\",\n        \"rate\": r\"\\Gamma\",\n        \"offset\": r\"b\",\n    }\n\n    @property\n    def tau(self) -&gt; _T:\n        return -1 / self.rate  # type: ignore # pylint: disable=E1101\n</code></pre> <p>Exp function.</p>"},{"location":"functions/exp/#ffit.funcs.exp.Exp--function","title":"Function","text":"\\[     f(x) = A \\exp(\u0393\u22c5x) + A_{\\text{offset}} \\] <pre><code>f(x) = amplitude * np.exp(rate * x) + offset\n</code></pre>"},{"location":"functions/exp/#ffit.funcs.exp.Exp--final-parameters","title":"Final parameters","text":"<p>The final parameters are given by <code>ExpParam</code> dataclass.</p> Source code in <code>ffit/funcs/exp.py</code> <pre><code>class Exp(FitLogic[ExpResult]):  # type: ignore\n    r\"\"\"Exp function.\n\n\n    Function\n    ---------\n\n    $$\n        f(x) = A \\exp(\u0393\u22c5x) + A_{\\text{offset}}\n    $$\n\n        f(x) = amplitude * np.exp(rate * x) + offset\n\n\n    Final parameters\n    -----------------\n    The final parameters are given by [`ExpParam`](../exp_param/) dataclass.\n\n    \"\"\"\n\n    _result_class: _t.Type[ExpResult] = ExpResult\n\n    func = staticmethod(exp_func)\n    func_std = staticmethod(exp_error)\n    _guess = staticmethod(exp_guess)\n\n    _example_param = (-3, -0.5, 3)\n    _example_x_min = 0\n    _example_x_max = 10\n\n    @_t.overload\n    @classmethod\n    def mask(  # type: ignore # pylint: disable=W0221\n        cls,\n        *,\n        amplitude: float = None,  # type: ignore\n        rate: float = None,  # type: ignore\n        offset: float = None,  # type: ignore\n    ) -&gt; \"Exp\": ...\n\n    @classmethod\n    def mask(cls, **kwargs) -&gt; \"Exp\":\n        return super().mask(**kwargs)\n</code></pre>"},{"location":"functions/exp/#ffit.funcs.exp.Exp.fit","title":"fit","text":"<pre><code>fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n    if len(x) != len(data):\n        raise ValueError(\"x and data must have the same length\")\n    if mask is not None and len(mask) != len(x):\n        raise ValueError(\"mask must have the same length as x and data\")\n\n    res, res_std = self._fit(\n        x,\n        data,\n        mask=mask,\n        guess=guess,\n        method=method,\n        maxfev=maxfev,\n        **kwargs,\n    )\n\n    # param = self.param(*res, std=res_std)\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    # print(res)\n    return self._result_class(\n        res,\n        lambda x: full_func(x, *res),\n        std=res_std,\n        x=x,\n        data=data,\n        stderr=res_std,\n        stdfunc=lambda x: self.get_func_std()(x, *res, *res_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/exp/#ffit.funcs.exp.Exp.async_fit","title":"async_fit  <code>async</code>","text":"<pre><code>async_fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Asynchronously fits the model to the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable data.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable data to fit.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>An optional mask to apply to the data. Defaults to None.</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>An optional initial guess for the fitting parameters. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the fitting function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>_T</code> <p>FitWithErrorResult[_T]: The result of the fitting process, including the fitted parameters and associated errors.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>async def async_fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"\n    Asynchronously fits the model to the provided data.\n\n    Args:\n        x (_ARRAY): The independent variable data.\n        data (_ARRAY): The dependent variable data to fit.\n        mask (Optional[Union[_ARRAY, float]], optional): An optional mask to apply to the data. Defaults to None.\n        guess (Optional[_T], optional): An optional initial guess for the fitting parameters. Defaults to None.\n        **kwargs: Additional keyword arguments to pass to the fitting function.\n\n    Returns:\n        FitWithErrorResult[_T]:\n            The result of the fitting process, including the fitted parameters and associated errors.\n    \"\"\"\n    return self.fit(\n        x, data, mask=mask, guess=guess, method=method, maxfev=maxfev, **kwargs\n    )\n</code></pre>"},{"location":"functions/exp/#ffit.funcs.exp.Exp.guess","title":"guess  <code>classmethod</code>","text":"<pre><code>guess(x, data, mask=None, guess=None, **kwargs)\n</code></pre> <p>Guess the initial fit parameters.</p> <p>This function returns an object of the class <code>FitResult</code>. See its documentation for more information on what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>The independent variable.</p> required <code>data</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>The initial guess for the fit parameters (optional).</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The guess, including the guess parameters and the function based on the guess.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n&gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n&gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n&gt;&gt;&gt; fit_guess.plot()\n</code></pre> Source code in <code>ffit/fit_logic.py</code> <pre><code>@classmethod\ndef guess(\n    cls,\n    x,\n    data,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Guess the initial fit parameters.\n\n    This function returns an object of the class `FitResult`.\n    See its documentation for more information on what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for the fit parameters (optional).\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The guess, including the guess parameters and the function based on the guess.\n\n    Examples:\n        &gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n        &gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n        &gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n        &gt;&gt;&gt; fit_guess.plot()\n    \"\"\"\n    if guess is not None:\n        return cls._result_class(\n            np.asarray(guess),\n            lambda x: cls.func(x, *guess),\n            x=x,\n            data=data,\n        )\n    x_masked, data_masked = get_masked_data(x, data, mask, mask_min_len=1)\n    guess_param = cls._guess(x_masked, data_masked, **kwargs)\n    return cls._result_class(\n        np.asarray(guess_param),\n        lambda x: cls.func(x, *guess_param),\n        x=x,\n        data=data,\n    )\n</code></pre>"},{"location":"functions/exp/#ffit.funcs.exp.Exp.bootstrapping","title":"bootstrapping","text":"<pre><code>bootstrapping(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, maxfev=_DEFAULT_MAXFEV, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, _ANY_LIST_LIKE]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>The number of permutations to use for the bootstrapping.</p> <code>None</code> <code>maxfev</code> <code>int</code> <p>The maximum number of function evaluations.</p> <code>_DEFAULT_MAXFEV</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, _ANY_LIST_LIKE]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    maxfev: int = _DEFAULT_MAXFEV,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        num_of_permutations: The number of permutations to use for the bootstrapping.\n        maxfev: The maximum number of function evaluations.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    res_means, total_std = self._bootstrapping(\n        x, data, mask, guess, method, num_of_permutations, maxfev\n    )\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/exp/#ffit.funcs.exp.Exp.array_bootstrapping","title":"array_bootstrapping","text":"<pre><code>array_bootstrapping(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, num_of_permutations=None, **kwargs)\n</code></pre> <p>Perform array bootstrapping in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>Number of bootstrap iterations.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the bootstrapping.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def array_bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array bootstrapping in parallel.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        num_of_permutations: Number of bootstrap iterations.\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the bootstrapping.\n    \"\"\"\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Run bootstrapping on each dataset\n    results = np.array(\n        [\n            self._bootstrapping(\n                x[i] if multi_x else x,\n                data[i],\n                mask=mask,\n                guess=guess,\n                method=method,\n                num_of_permutations=num_of_permutations,\n                maxfev=maxfev,\n                **kwargs,\n            )\n            for i in range(len(data))\n        ]\n    )\n\n    # Split means and stds from results\n    result_means = results[:, 0, :]  # First element of each result is means\n    result_stds = results[:, 1, :]  # Second element is standard deviations\n\n    # Reshape results back to original data shape\n    result_means = result_means.reshape(data_shape[:-1] + (-1,))\n    result_stds = result_stds.reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        result_means,\n        self._create_array_res_func(\n            result_means, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        stderr=result_stds,\n        stdfunc=lambda x: self.get_func_std()(x, *result_means, *result_stds),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/exp/#ffit.funcs.exp.Exp.bootstrapping2D","title":"bootstrapping2D","text":"<pre><code>bootstrapping2D(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The 2D dependent variable (data, batches).</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping2D(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The 2D dependent variable (data, batches).\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    # Mask the data and check that length of masked data is greater than lens of params\n    x_masked, data_masked = get_masked_data(x, data, mask, self._param_len)\n    if len(x_masked) == 0 or len(data_masked) == 0:\n        return self._result_class(\n            np.ones(self._param_len) * np.nan,\n            x=x,\n            data=data,\n        )\n\n    # Get a guess if not provided\n    if guess is None:\n        guess = self._guess(x_masked, np.mean(data_masked, axis=-1), **kwargs)\n\n    # Fit ones to get the best initial guess\n    guess, cov = self._run_fit(\n        x_masked, np.mean(data_masked, axis=-1), guess, method\n    )\n\n    # Run fit on random subarrays\n    all_res = []\n    total_elements = data_masked.shape[1]\n    if num_of_permutations is None:\n        num_of_permutations = int(min(max(total_elements / 10, 1_000), 5_000))\n\n    for selected_index in bootstrap_generator(total_elements, num_of_permutations):\n        res, _ = self._run_fit(\n            x_masked,\n            np.mean(data_masked[:, selected_index], axis=-1),\n            guess,\n            method,\n        )\n        if self.normalize_res is not None:  # type: ignore\n            res = self.normalize_res(res)  # type: ignore\n        all_res.append(res)\n\n    res_means = np.mean(all_res, axis=0)\n    bootstrap_std = np.std(all_res, axis=0)\n    total_std = bootstrap_std\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        cov=cov,  # type: ignore\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/exp/#ffit.funcs.exp.Exp.mp_array_fit","title":"mp_array_fit","text":"<pre><code>mp_array_fit(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, n_jobs=None, **kwargs)\n</code></pre> <p>Perform array fitting in parallel using multiprocessing.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>n_jobs</code> <code>Optional[int]</code> <p>Number of processes to use. If None, uses cpu_count().</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def mp_array_fit(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_t.Union[_ARRAY, float]] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    n_jobs: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array fitting in parallel using multiprocessing.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        n_jobs: Number of processes to use. If None, uses cpu_count().\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the fit.\n    \"\"\"\n    import multiprocessing as mp\n\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Prepare arguments for parallel processing\n    fit_args = [\n        (x[i] if multi_x else x, data[i], mask, guess, method, maxfev, kwargs)\n        for i in range(len(data))\n    ]\n\n    # Run fits in parallel using multiprocessing\n    with mp.Pool(processes=n_jobs) as pool:\n        results = pool.map(self._fit_worker, fit_args)\n\n    results = np.array(results).reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        results,\n        self._create_array_res_func(\n            results, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/exp_decaying_cos/","title":"ExpDecayingCos","text":""},{"location":"functions/exp_decaying_cos/#simples-example","title":"Simples example","text":"<pre><code>&gt;&gt;&gt; from ffit.funcs.exp_decaying_cos import ExpDecayingCos\n\n# Call the fit method with x and y data.\n&gt;&gt;&gt; fit_result = ExpDecayingCos().fit(x, y)\n\n# The result is a FitResult object that can be unpacked.\n&gt;&gt;&gt; res, res_func = fit_result.res_and_func()\n\n# The parameters can be accessed as attributes.\n&gt;&gt; amplitude0 = fit_result.amplitude0\n\n# One can combine multiple calls in one line.\n&gt;&gt;&gt; res = ExpDecayingCos().fit(x, y, guess=[1, 2, 3, 4]).plot(ax)\n</code></pre>"},{"location":"functions/exp_decaying_cos/#final-parameters","title":"Final parameters","text":"<p>Exponential Decaying Cosine parameters.</p> <p>Attributes:</p> Name Type Description <code>amplitude0</code> <code>float</code> <p>The absolute amplitude of the decaying cosine.</p> <code>frequency</code> <code>float</code> <p>The frequency of the decaying cosine.</p> <code>phi0</code> <code>float</code> <p>The initial phase of the decaying cosine.</p> <code>offset</code> <code>float</code> <p>The offset of the decaying cosine.</p> <code>tau</code> <code>float</code> <p>The decay constant of the decaying cosine.</p> <code>std</code> <code>Optional[ExpDecayingCosParam]</code> <p>The standard deviation of the parameters, if any.</p> Additional attributes <p>omega (float):     Calculates the angular frequency based on the frequency. rate (float):     Calculates the rate of decay.</p> Source code in <code>ffit/funcs/exp_decaying_cos.py</code> <pre><code>class ExpDecayingCosParam(_t.Generic[_T], FuncParamClass):\n    \"\"\"Exponential Decaying Cosine parameters.\n\n    Attributes:\n        amplitude0 (float):\n            The absolute amplitude of the decaying cosine.\n        frequency (float):\n            The frequency of the decaying cosine.\n        phi0 (float):\n            The initial phase of the decaying cosine.\n        offset (float):\n            The offset of the decaying cosine.\n        tau (float):\n            The decay constant of the decaying cosine.\n        std (Optional[ExpDecayingCosParam]):\n            The standard deviation of the parameters, if any.\n\n    Additional attributes:\n        omega (float):\n            Calculates the angular frequency based on the frequency.\n        rate (float):\n            Calculates the rate of decay.\n    \"\"\"\n\n    keys = (\"amplitude0\", \"frequency\", \"phi0\", \"offset\", \"tau\")\n\n    amplitude0: _T\n    frequency: _T\n    phi0: _T\n    offset: _T\n    tau: _T\n\n    __latex_repr__ = (\n        r\"$&amp;amplitude0 \\cdot \\cos(2\\pi \\cdot &amp;frequency \\cdot x + &amp;phi0) \\cdot \"\n        r\"e^{-x/&amp;tau} + &amp;offset$\"\n    )\n    __latex_repr_symbols__ = {\n        \"amplitude0\": r\"A_0\",\n        \"frequency\": r\"f\",\n        \"phi0\": r\"\\phi_0\",\n        \"offset\": r\"A_{\\text{offset}}\",\n        \"tau\": r\"\\tau\",\n    }\n\n    @property\n    def omega(self) -&gt; _T:\n        return 2 * np.pi * self.frequency  # pylint: disable=E1101  # type: ignore\n\n    @property\n    def rate(self) -&gt; _T:\n        return -1 / self.tau  # pylint: disable=E1101  # type: ignore\n</code></pre> <p>Fit ExpDecayingCos function.</p> <p>Function</p> <p>$$  f(x) = A_0 * \\cos(\u03c9\u22c5x + \\phi_0) * \\exp(-x / \u03c4) + A_{\\text{offset}}  $$</p> <pre><code> f(x) = (\n     amplitude0 * np.exp(-x / tau)\n     * np.cos(2 * np.pi * x * frequency + phi0)\n     + offset\n )\n</code></pre>"},{"location":"functions/exp_decaying_cos/#ffit.funcs.exp_decaying_cos.ExpDecayingCos--final-parameters","title":"Final parameters","text":"<p>The final parameters are given by <code>ExpDecayingCosParam</code> dataclass.</p> Source code in <code>ffit/funcs/exp_decaying_cos.py</code> <pre><code>class ExpDecayingCos(FitLogic[ExpDecayingCosResult]):  # type: ignore\n    r\"\"\"Fit ExpDecayingCos function.\n\n\n     Function\n     ---------\n\n     $$\n     f(x) = A_0 * \\cos(\u03c9\u22c5x + \\phi_0) * \\exp(-x / \u03c4) + A_{\\text{offset}}\n     $$\n\n         f(x) = (\n             amplitude0 * np.exp(-x / tau)\n             * np.cos(2 * np.pi * x * frequency + phi0)\n             + offset\n         )\n\n\n     Final parameters\n    -----------------\n     The final parameters are given by [`ExpDecayingCosParam`](../exp_decaying_cos_param/) dataclass.\n\n    \"\"\"\n\n    _result_class: _t.Type[ExpDecayingCosResult] = ExpDecayingCosResult\n\n    func = staticmethod(exp_decaying_cos_func)\n    # func_std = staticmethod(cos_error)\n\n    normalize_res = staticmethod(normalize_res_list)\n    _guess = staticmethod(exp_decaying_cos_guess)\n\n    @_t.overload\n    @classmethod\n    def mask(  # type: ignore # pylint: disable=W0221\n        cls,\n        *,\n        amplitude0: float = None,  # type: ignore\n        frequency: float = None,  # type: ignore\n        phi0: float = None,  # type: ignore\n        offset: float = None,  # type: ignore\n        tau: float = None,  # type: ignore\n    ) -&gt; \"ExpDecayingCos\": ...\n\n    @classmethod\n    def mask(cls, **kwargs) -&gt; \"ExpDecayingCos\":\n        return super().mask(**kwargs)\n\n    _range_x = (0, np.inf)\n</code></pre>"},{"location":"functions/exp_decaying_cos/#ffit.funcs.exp_decaying_cos.ExpDecayingCos.fit","title":"fit","text":"<pre><code>fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n    if len(x) != len(data):\n        raise ValueError(\"x and data must have the same length\")\n    if mask is not None and len(mask) != len(x):\n        raise ValueError(\"mask must have the same length as x and data\")\n\n    res, res_std = self._fit(\n        x,\n        data,\n        mask=mask,\n        guess=guess,\n        method=method,\n        maxfev=maxfev,\n        **kwargs,\n    )\n\n    # param = self.param(*res, std=res_std)\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    # print(res)\n    return self._result_class(\n        res,\n        lambda x: full_func(x, *res),\n        std=res_std,\n        x=x,\n        data=data,\n        stderr=res_std,\n        stdfunc=lambda x: self.get_func_std()(x, *res, *res_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/exp_decaying_cos/#ffit.funcs.exp_decaying_cos.ExpDecayingCos.async_fit","title":"async_fit  <code>async</code>","text":"<pre><code>async_fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Asynchronously fits the model to the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable data.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable data to fit.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>An optional mask to apply to the data. Defaults to None.</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>An optional initial guess for the fitting parameters. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the fitting function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>_T</code> <p>FitWithErrorResult[_T]: The result of the fitting process, including the fitted parameters and associated errors.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>async def async_fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"\n    Asynchronously fits the model to the provided data.\n\n    Args:\n        x (_ARRAY): The independent variable data.\n        data (_ARRAY): The dependent variable data to fit.\n        mask (Optional[Union[_ARRAY, float]], optional): An optional mask to apply to the data. Defaults to None.\n        guess (Optional[_T], optional): An optional initial guess for the fitting parameters. Defaults to None.\n        **kwargs: Additional keyword arguments to pass to the fitting function.\n\n    Returns:\n        FitWithErrorResult[_T]:\n            The result of the fitting process, including the fitted parameters and associated errors.\n    \"\"\"\n    return self.fit(\n        x, data, mask=mask, guess=guess, method=method, maxfev=maxfev, **kwargs\n    )\n</code></pre>"},{"location":"functions/exp_decaying_cos/#ffit.funcs.exp_decaying_cos.ExpDecayingCos.guess","title":"guess  <code>classmethod</code>","text":"<pre><code>guess(x, data, mask=None, guess=None, **kwargs)\n</code></pre> <p>Guess the initial fit parameters.</p> <p>This function returns an object of the class <code>FitResult</code>. See its documentation for more information on what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>The independent variable.</p> required <code>data</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>The initial guess for the fit parameters (optional).</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The guess, including the guess parameters and the function based on the guess.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n&gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n&gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n&gt;&gt;&gt; fit_guess.plot()\n</code></pre> Source code in <code>ffit/fit_logic.py</code> <pre><code>@classmethod\ndef guess(\n    cls,\n    x,\n    data,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Guess the initial fit parameters.\n\n    This function returns an object of the class `FitResult`.\n    See its documentation for more information on what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for the fit parameters (optional).\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The guess, including the guess parameters and the function based on the guess.\n\n    Examples:\n        &gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n        &gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n        &gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n        &gt;&gt;&gt; fit_guess.plot()\n    \"\"\"\n    if guess is not None:\n        return cls._result_class(\n            np.asarray(guess),\n            lambda x: cls.func(x, *guess),\n            x=x,\n            data=data,\n        )\n    x_masked, data_masked = get_masked_data(x, data, mask, mask_min_len=1)\n    guess_param = cls._guess(x_masked, data_masked, **kwargs)\n    return cls._result_class(\n        np.asarray(guess_param),\n        lambda x: cls.func(x, *guess_param),\n        x=x,\n        data=data,\n    )\n</code></pre>"},{"location":"functions/exp_decaying_cos/#ffit.funcs.exp_decaying_cos.ExpDecayingCos.bootstrapping","title":"bootstrapping","text":"<pre><code>bootstrapping(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, maxfev=_DEFAULT_MAXFEV, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, _ANY_LIST_LIKE]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>The number of permutations to use for the bootstrapping.</p> <code>None</code> <code>maxfev</code> <code>int</code> <p>The maximum number of function evaluations.</p> <code>_DEFAULT_MAXFEV</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, _ANY_LIST_LIKE]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    maxfev: int = _DEFAULT_MAXFEV,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        num_of_permutations: The number of permutations to use for the bootstrapping.\n        maxfev: The maximum number of function evaluations.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    res_means, total_std = self._bootstrapping(\n        x, data, mask, guess, method, num_of_permutations, maxfev\n    )\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/exp_decaying_cos/#ffit.funcs.exp_decaying_cos.ExpDecayingCos.array_bootstrapping","title":"array_bootstrapping","text":"<pre><code>array_bootstrapping(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, num_of_permutations=None, **kwargs)\n</code></pre> <p>Perform array bootstrapping in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>Number of bootstrap iterations.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the bootstrapping.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def array_bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array bootstrapping in parallel.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        num_of_permutations: Number of bootstrap iterations.\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the bootstrapping.\n    \"\"\"\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Run bootstrapping on each dataset\n    results = np.array(\n        [\n            self._bootstrapping(\n                x[i] if multi_x else x,\n                data[i],\n                mask=mask,\n                guess=guess,\n                method=method,\n                num_of_permutations=num_of_permutations,\n                maxfev=maxfev,\n                **kwargs,\n            )\n            for i in range(len(data))\n        ]\n    )\n\n    # Split means and stds from results\n    result_means = results[:, 0, :]  # First element of each result is means\n    result_stds = results[:, 1, :]  # Second element is standard deviations\n\n    # Reshape results back to original data shape\n    result_means = result_means.reshape(data_shape[:-1] + (-1,))\n    result_stds = result_stds.reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        result_means,\n        self._create_array_res_func(\n            result_means, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        stderr=result_stds,\n        stdfunc=lambda x: self.get_func_std()(x, *result_means, *result_stds),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/exp_decaying_cos/#ffit.funcs.exp_decaying_cos.ExpDecayingCos.bootstrapping2D","title":"bootstrapping2D","text":"<pre><code>bootstrapping2D(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The 2D dependent variable (data, batches).</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping2D(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The 2D dependent variable (data, batches).\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    # Mask the data and check that length of masked data is greater than lens of params\n    x_masked, data_masked = get_masked_data(x, data, mask, self._param_len)\n    if len(x_masked) == 0 or len(data_masked) == 0:\n        return self._result_class(\n            np.ones(self._param_len) * np.nan,\n            x=x,\n            data=data,\n        )\n\n    # Get a guess if not provided\n    if guess is None:\n        guess = self._guess(x_masked, np.mean(data_masked, axis=-1), **kwargs)\n\n    # Fit ones to get the best initial guess\n    guess, cov = self._run_fit(\n        x_masked, np.mean(data_masked, axis=-1), guess, method\n    )\n\n    # Run fit on random subarrays\n    all_res = []\n    total_elements = data_masked.shape[1]\n    if num_of_permutations is None:\n        num_of_permutations = int(min(max(total_elements / 10, 1_000), 5_000))\n\n    for selected_index in bootstrap_generator(total_elements, num_of_permutations):\n        res, _ = self._run_fit(\n            x_masked,\n            np.mean(data_masked[:, selected_index], axis=-1),\n            guess,\n            method,\n        )\n        if self.normalize_res is not None:  # type: ignore\n            res = self.normalize_res(res)  # type: ignore\n        all_res.append(res)\n\n    res_means = np.mean(all_res, axis=0)\n    bootstrap_std = np.std(all_res, axis=0)\n    total_std = bootstrap_std\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        cov=cov,  # type: ignore\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/exp_decaying_cos/#ffit.funcs.exp_decaying_cos.ExpDecayingCos.mp_array_fit","title":"mp_array_fit","text":"<pre><code>mp_array_fit(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, n_jobs=None, **kwargs)\n</code></pre> <p>Perform array fitting in parallel using multiprocessing.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>n_jobs</code> <code>Optional[int]</code> <p>Number of processes to use. If None, uses cpu_count().</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def mp_array_fit(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_t.Union[_ARRAY, float]] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    n_jobs: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array fitting in parallel using multiprocessing.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        n_jobs: Number of processes to use. If None, uses cpu_count().\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the fit.\n    \"\"\"\n    import multiprocessing as mp\n\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Prepare arguments for parallel processing\n    fit_args = [\n        (x[i] if multi_x else x, data[i], mask, guess, method, maxfev, kwargs)\n        for i in range(len(data))\n    ]\n\n    # Run fits in parallel using multiprocessing\n    with mp.Pool(processes=n_jobs) as pool:\n        results = pool.map(self._fit_worker, fit_args)\n\n    results = np.array(results).reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        results,\n        self._create_array_res_func(\n            results, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/gaussian/","title":"Gaussian","text":""},{"location":"functions/gaussian/#simples-example","title":"Simples example","text":"<pre><code>&gt;&gt;&gt; from ffit.funcs.gaussian import Gaussian\n\n# Call the fit method with x and y data.\n&gt;&gt;&gt; fit_result = Gaussian().fit(x, y)\n\n# The result is a FitResult object that can be unpacked.\n&gt;&gt;&gt; res, res_func = fit_result.res_and_func()\n\n# The parameters can be accessed as attributes.\n&gt;&gt; mu = fit_result.mu\n\n# One can combine multiple calls in one line.\n&gt;&gt;&gt; res = Gaussian().fit(x, y, guess=[1, 2, 3, 4]).plot(ax)\n</code></pre>"},{"location":"functions/gaussian/#final-parameters","title":"Final parameters","text":"<p>Gaussian parameters.</p> <pre><code>mu (float):\n    The  Gaussian peak.\nsigma (float):\n    The sqrt of the standard deviation.\namplitude (float):\n    Teh normalization factor.\noffset (float):\n    The baseline offset from zero.\n</code></pre> <p>Attention to use <code>sigma</code> and not <code>std</code>, as it is reserved for standard deviation of the parameters.</p> Source code in <code>ffit/funcs/gaussian.py</code> <pre><code>class GaussianParam(_t.Generic[_T], FuncParamClass):\n    \"\"\"Gaussian parameters.\n\n    Attributes:\n    -----------------\n        mu (float):\n            The  Gaussian peak.\n        sigma (float):\n            The sqrt of the standard deviation.\n        amplitude (float):\n            Teh normalization factor.\n        offset (float):\n            The baseline offset from zero.\n\n    Attention to use `sigma` and not `std`, as it is reserved for standard deviation of the parameters.\n    \"\"\"\n\n    keys = (\"mu\", \"sigma\", \"amplitude\", \"offset\")\n\n    mu: _T\n    sigma: _T\n    amplitude: _T\n    offset: _T\n\n    __latex_repr__ = (\n        r\"$\\frac{&amp;amplitude}{\\sqrt{2\\pi}\\,&amp;sigma}\"\n        r\"\\exp\\left(-\\frac{(x - &amp;mu)^2}{2 &amp;sigma^2}\\right) + &amp;offset$\"\n    )\n    __latex_repr_symbols__ = {\n        \"amplitude\": r\"A\",\n        \"sigma\": r\"\\sigma\",\n        \"mu\": r\"\\mu\",\n        \"offset\": r\"b\",\n    }\n</code></pre>"},{"location":"functions/gaussian/#ffit.funcs.gaussian.Gaussian--gaussian-function","title":"Gaussian function.","text":"\\[ a \\cdot \\frac{A}{\\sqrt{2\\pi}\\sigma} \\cdot \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right) + b \\] <pre><code>f(x) = (\n    amplitude\n    * np.exp(-((x - mu) ** 2) / (2 * sigma**2))\n    / np.sqrt(2 * np.pi)\n    / sigma\n    + offset\n)\n</code></pre>"},{"location":"functions/gaussian/#ffit.funcs.gaussian.Gaussian--example","title":"Example","text":"<pre><code>&gt;&gt;&gt; import ffit as ff\n&gt;&gt;&gt; res = ff.Gaussian().fit(x, y).res\n\n&gt;&gt;&gt; res = ff.Gaussian().fit(x, y, guess=[1, 2, 3, 4]).plot(ax).res\n&gt;&gt;&gt; mu = res.mu\n</code></pre>"},{"location":"functions/gaussian/#ffit.funcs.gaussian.Gaussian--final-parameters","title":"Final parameters","text":"<p>The final parameters are given by <code>GaussianParam</code> dataclass.</p> Source code in <code>ffit/funcs/gaussian.py</code> <pre><code>class Gaussian(FitLogic[GaussianResult]):  # type: ignore\n    r\"\"\"Gaussian function.\n    ---------\n\n    $$\n    a \\cdot \\frac{A}{\\sqrt{2\\pi}\\sigma} \\cdot \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right) + b\n    $$\n\n        f(x) = (\n            amplitude\n            * np.exp(-((x - mu) ** 2) / (2 * sigma**2))\n            / np.sqrt(2 * np.pi)\n            / sigma\n            + offset\n        )\n\n    Example\n    -------\n        &gt;&gt;&gt; import ffit as ff\n        &gt;&gt;&gt; res = ff.Gaussian().fit(x, y).res\n\n        &gt;&gt;&gt; res = ff.Gaussian().fit(x, y, guess=[1, 2, 3, 4]).plot(ax).res\n        &gt;&gt;&gt; mu = res.mu\n\n    Final parameters\n    -----------------\n    The final parameters are given by [`GaussianParam`](../gaussian_param/) dataclass.\n    \"\"\"\n\n    _result_class: _t.Type[GaussianResult] = GaussianResult\n\n    func = staticmethod(gaussian_func)\n    _guess = staticmethod(gaussian_guess)\n    normalize_res = staticmethod(normalize_res_list)\n\n    _example_param = (0.2, 0.2, 0.2, 0.2)\n\n    @_t.overload\n    @classmethod\n    def mask(  # type: ignore # pylint: disable=W0221\n        cls,\n        *,\n        mu: float = None,  # type: ignore\n        sigma: float = None,  # type: ignore\n        amplitude: float = None,  # type: ignore\n        offset: float = None,  # type: ignore\n    ) -&gt; \"Gaussian\": ...\n\n    @classmethod\n    def mask(cls, **kwargs) -&gt; \"Gaussian\":\n        return super().mask(**kwargs)\n</code></pre>"},{"location":"functions/gaussian/#ffit.funcs.gaussian.Gaussian.fit","title":"fit","text":"<pre><code>fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n    if len(x) != len(data):\n        raise ValueError(\"x and data must have the same length\")\n    if mask is not None and len(mask) != len(x):\n        raise ValueError(\"mask must have the same length as x and data\")\n\n    res, res_std = self._fit(\n        x,\n        data,\n        mask=mask,\n        guess=guess,\n        method=method,\n        maxfev=maxfev,\n        **kwargs,\n    )\n\n    # param = self.param(*res, std=res_std)\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    # print(res)\n    return self._result_class(\n        res,\n        lambda x: full_func(x, *res),\n        std=res_std,\n        x=x,\n        data=data,\n        stderr=res_std,\n        stdfunc=lambda x: self.get_func_std()(x, *res, *res_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/gaussian/#ffit.funcs.gaussian.Gaussian.async_fit","title":"async_fit  <code>async</code>","text":"<pre><code>async_fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Asynchronously fits the model to the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable data.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable data to fit.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>An optional mask to apply to the data. Defaults to None.</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>An optional initial guess for the fitting parameters. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the fitting function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>_T</code> <p>FitWithErrorResult[_T]: The result of the fitting process, including the fitted parameters and associated errors.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>async def async_fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"\n    Asynchronously fits the model to the provided data.\n\n    Args:\n        x (_ARRAY): The independent variable data.\n        data (_ARRAY): The dependent variable data to fit.\n        mask (Optional[Union[_ARRAY, float]], optional): An optional mask to apply to the data. Defaults to None.\n        guess (Optional[_T], optional): An optional initial guess for the fitting parameters. Defaults to None.\n        **kwargs: Additional keyword arguments to pass to the fitting function.\n\n    Returns:\n        FitWithErrorResult[_T]:\n            The result of the fitting process, including the fitted parameters and associated errors.\n    \"\"\"\n    return self.fit(\n        x, data, mask=mask, guess=guess, method=method, maxfev=maxfev, **kwargs\n    )\n</code></pre>"},{"location":"functions/gaussian/#ffit.funcs.gaussian.Gaussian.guess","title":"guess  <code>classmethod</code>","text":"<pre><code>guess(x, data, mask=None, guess=None, **kwargs)\n</code></pre> <p>Guess the initial fit parameters.</p> <p>This function returns an object of the class <code>FitResult</code>. See its documentation for more information on what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>The independent variable.</p> required <code>data</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>The initial guess for the fit parameters (optional).</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The guess, including the guess parameters and the function based on the guess.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n&gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n&gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n&gt;&gt;&gt; fit_guess.plot()\n</code></pre> Source code in <code>ffit/fit_logic.py</code> <pre><code>@classmethod\ndef guess(\n    cls,\n    x,\n    data,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Guess the initial fit parameters.\n\n    This function returns an object of the class `FitResult`.\n    See its documentation for more information on what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for the fit parameters (optional).\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The guess, including the guess parameters and the function based on the guess.\n\n    Examples:\n        &gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n        &gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n        &gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n        &gt;&gt;&gt; fit_guess.plot()\n    \"\"\"\n    if guess is not None:\n        return cls._result_class(\n            np.asarray(guess),\n            lambda x: cls.func(x, *guess),\n            x=x,\n            data=data,\n        )\n    x_masked, data_masked = get_masked_data(x, data, mask, mask_min_len=1)\n    guess_param = cls._guess(x_masked, data_masked, **kwargs)\n    return cls._result_class(\n        np.asarray(guess_param),\n        lambda x: cls.func(x, *guess_param),\n        x=x,\n        data=data,\n    )\n</code></pre>"},{"location":"functions/gaussian/#ffit.funcs.gaussian.Gaussian.bootstrapping","title":"bootstrapping","text":"<pre><code>bootstrapping(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, maxfev=_DEFAULT_MAXFEV, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, _ANY_LIST_LIKE]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>The number of permutations to use for the bootstrapping.</p> <code>None</code> <code>maxfev</code> <code>int</code> <p>The maximum number of function evaluations.</p> <code>_DEFAULT_MAXFEV</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, _ANY_LIST_LIKE]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    maxfev: int = _DEFAULT_MAXFEV,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        num_of_permutations: The number of permutations to use for the bootstrapping.\n        maxfev: The maximum number of function evaluations.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    res_means, total_std = self._bootstrapping(\n        x, data, mask, guess, method, num_of_permutations, maxfev\n    )\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/gaussian/#ffit.funcs.gaussian.Gaussian.array_bootstrapping","title":"array_bootstrapping","text":"<pre><code>array_bootstrapping(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, num_of_permutations=None, **kwargs)\n</code></pre> <p>Perform array bootstrapping in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>Number of bootstrap iterations.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the bootstrapping.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def array_bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array bootstrapping in parallel.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        num_of_permutations: Number of bootstrap iterations.\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the bootstrapping.\n    \"\"\"\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Run bootstrapping on each dataset\n    results = np.array(\n        [\n            self._bootstrapping(\n                x[i] if multi_x else x,\n                data[i],\n                mask=mask,\n                guess=guess,\n                method=method,\n                num_of_permutations=num_of_permutations,\n                maxfev=maxfev,\n                **kwargs,\n            )\n            for i in range(len(data))\n        ]\n    )\n\n    # Split means and stds from results\n    result_means = results[:, 0, :]  # First element of each result is means\n    result_stds = results[:, 1, :]  # Second element is standard deviations\n\n    # Reshape results back to original data shape\n    result_means = result_means.reshape(data_shape[:-1] + (-1,))\n    result_stds = result_stds.reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        result_means,\n        self._create_array_res_func(\n            result_means, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        stderr=result_stds,\n        stdfunc=lambda x: self.get_func_std()(x, *result_means, *result_stds),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/gaussian/#ffit.funcs.gaussian.Gaussian.bootstrapping2D","title":"bootstrapping2D","text":"<pre><code>bootstrapping2D(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The 2D dependent variable (data, batches).</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping2D(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The 2D dependent variable (data, batches).\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    # Mask the data and check that length of masked data is greater than lens of params\n    x_masked, data_masked = get_masked_data(x, data, mask, self._param_len)\n    if len(x_masked) == 0 or len(data_masked) == 0:\n        return self._result_class(\n            np.ones(self._param_len) * np.nan,\n            x=x,\n            data=data,\n        )\n\n    # Get a guess if not provided\n    if guess is None:\n        guess = self._guess(x_masked, np.mean(data_masked, axis=-1), **kwargs)\n\n    # Fit ones to get the best initial guess\n    guess, cov = self._run_fit(\n        x_masked, np.mean(data_masked, axis=-1), guess, method\n    )\n\n    # Run fit on random subarrays\n    all_res = []\n    total_elements = data_masked.shape[1]\n    if num_of_permutations is None:\n        num_of_permutations = int(min(max(total_elements / 10, 1_000), 5_000))\n\n    for selected_index in bootstrap_generator(total_elements, num_of_permutations):\n        res, _ = self._run_fit(\n            x_masked,\n            np.mean(data_masked[:, selected_index], axis=-1),\n            guess,\n            method,\n        )\n        if self.normalize_res is not None:  # type: ignore\n            res = self.normalize_res(res)  # type: ignore\n        all_res.append(res)\n\n    res_means = np.mean(all_res, axis=0)\n    bootstrap_std = np.std(all_res, axis=0)\n    total_std = bootstrap_std\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        cov=cov,  # type: ignore\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/gaussian/#ffit.funcs.gaussian.Gaussian.mp_array_fit","title":"mp_array_fit","text":"<pre><code>mp_array_fit(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, n_jobs=None, **kwargs)\n</code></pre> <p>Perform array fitting in parallel using multiprocessing.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>n_jobs</code> <code>Optional[int]</code> <p>Number of processes to use. If None, uses cpu_count().</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def mp_array_fit(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_t.Union[_ARRAY, float]] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    n_jobs: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array fitting in parallel using multiprocessing.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        n_jobs: Number of processes to use. If None, uses cpu_count().\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the fit.\n    \"\"\"\n    import multiprocessing as mp\n\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Prepare arguments for parallel processing\n    fit_args = [\n        (x[i] if multi_x else x, data[i], mask, guess, method, maxfev, kwargs)\n        for i in range(len(data))\n    ]\n\n    # Run fits in parallel using multiprocessing\n    with mp.Pool(processes=n_jobs) as pool:\n        results = pool.map(self._fit_worker, fit_args)\n\n    results = np.array(results).reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        results,\n        self._create_array_res_func(\n            results, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/hyperbola/","title":"Hyperbola","text":""},{"location":"functions/hyperbola/#simples-example","title":"Simples example","text":"<pre><code>&gt;&gt;&gt; from ffit.funcs.hyperbola import Hyperbola\n\n# Call the fit method with x and y data.\n&gt;&gt;&gt; fit_result = Hyperbola().fit(x, y)\n\n# The result is a FitResult object that can be unpacked.\n&gt;&gt;&gt; res, res_func = fit_result.res_and_func()\n\n# The parameters can be accessed as attributes.\n&gt;&gt; semix = fit_result.semix\n\n# One can combine multiple calls in one line.\n&gt;&gt;&gt; res = Hyperbola().fit(x, y, guess=[1, 2, 3, 4]).plot(ax)\n</code></pre>"},{"location":"functions/hyperbola/#final-parameters","title":"Final parameters","text":"<p>Hyperbola parameters.</p> <p>Attributes:</p> Name Type Description <code>semix</code> <code>float</code> <p>The semi-major axis length of the hyperbola.</p> <code>semiy</code> <code>float</code> <p>The semi-minor axis length of the hyperbola.</p> <code>x0</code> <code>float</code> <p>The x-coordinate of the hyperbola's center.</p> <code>y0</code> <code>float</code> <p>The y-coordinate of the hyperbola's center.</p> <code>std</code> <code>Optional[HyperbolaParam]</code> <p>The standard deviation of the hyperbola parameters.</p> Source code in <code>ffit/funcs/hyperbola.py</code> <pre><code>class HyperbolaParam(_t.Generic[_T], FuncParamClass):\n    \"\"\"Hyperbola parameters.\n\n    Attributes:\n        semix (float):\n            The semi-major axis length of the hyperbola.\n        semiy (float):\n            The semi-minor axis length of the hyperbola.\n        x0 (float):\n            The x-coordinate of the hyperbola's center.\n        y0 (float):\n            The y-coordinate of the hyperbola's center.\n        std (Optional[HyperbolaParam]):\n            The standard deviation of the hyperbola parameters.\n    \"\"\"\n\n    keys = (\"semix\", \"semiy\", \"x0\", \"y0\")\n\n    semix: _T\n    semiy: _T\n    x0: _T\n    y0: _T\n\n    __latex_repr__ = (\n        r\"$&amp;y0 + &amp;semiy \\cdot \\sqrt{1 + \\left(\\frac{x - &amp;x0}{&amp;semix}\\right)^2}$\"\n    )\n    __latex_repr_symbols__ = {\n        \"semix\": r\"a\",\n        \"semiy\": r\"b\",\n        \"x0\": r\"x_0\",\n        \"y0\": r\"y_0\",\n    }\n</code></pre>"},{"location":"functions/hyperbola/#ffit.funcs.hyperbola.Hyperbola--hyperbola-function","title":"Hyperbola function.","text":"\\[ \\frac{(x - x0)^2}{semix^2} - \\frac{(y - y0)^2}{semiy^2} = 1 \\] <pre><code>f(x) = y0 + semiy * np.sqrt(1 + ((x - x0) / semix) ** 2)\n</code></pre>"},{"location":"functions/hyperbola/#ffit.funcs.hyperbola.Hyperbola--final-parameters","title":"Final parameters","text":"<p>The final parameters are given by <code>HyperbolaParam</code> dataclass.</p> Source code in <code>ffit/funcs/hyperbola.py</code> <pre><code>class Hyperbola(FitLogic[HyperbolaResult]):  # type: ignore\n    r\"\"\"Hyperbola function.\n    ---------\n\n    $$\n    \\frac{(x - x0)^2}{semix^2} - \\frac{(y - y0)^2}{semiy^2} = 1\n    $$\n\n        f(x) = y0 + semiy * np.sqrt(1 + ((x - x0) / semix) ** 2)\n\n    Final parameters\n    -----------------\n    The final parameters are given by [`HyperbolaParam`](../hyperbola_param/) dataclass.\n\n    \"\"\"\n\n    _result_class: _t.Type[HyperbolaResult] = HyperbolaResult\n\n    func = staticmethod(hyperbola_func)\n    _guess = staticmethod(hyperbola_guess)\n    normalize_res = staticmethod(normalize_res_list)\n\n    _example_param = (1, 2, 0, 0.5)\n    _example_x_min = -5\n    _example_x_max = 5\n\n    @_t.overload\n    @classmethod\n    def mask(  # type: ignore # pylint: disable=W0221\n        cls,\n        *,\n        semix: float = None,  # type: ignore\n        semiy: float = None,  # type: ignore\n        x0: float = None,  # type: ignore\n        y0: float = None,  # type: ignore\n    ) -&gt; \"Hyperbola\": ...\n\n    @classmethod\n    def mask(cls, **kwargs) -&gt; \"Hyperbola\":\n        return super().mask(**kwargs)\n</code></pre>"},{"location":"functions/hyperbola/#ffit.funcs.hyperbola.Hyperbola.fit","title":"fit","text":"<pre><code>fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n    if len(x) != len(data):\n        raise ValueError(\"x and data must have the same length\")\n    if mask is not None and len(mask) != len(x):\n        raise ValueError(\"mask must have the same length as x and data\")\n\n    res, res_std = self._fit(\n        x,\n        data,\n        mask=mask,\n        guess=guess,\n        method=method,\n        maxfev=maxfev,\n        **kwargs,\n    )\n\n    # param = self.param(*res, std=res_std)\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    # print(res)\n    return self._result_class(\n        res,\n        lambda x: full_func(x, *res),\n        std=res_std,\n        x=x,\n        data=data,\n        stderr=res_std,\n        stdfunc=lambda x: self.get_func_std()(x, *res, *res_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/hyperbola/#ffit.funcs.hyperbola.Hyperbola.async_fit","title":"async_fit  <code>async</code>","text":"<pre><code>async_fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Asynchronously fits the model to the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable data.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable data to fit.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>An optional mask to apply to the data. Defaults to None.</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>An optional initial guess for the fitting parameters. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the fitting function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>_T</code> <p>FitWithErrorResult[_T]: The result of the fitting process, including the fitted parameters and associated errors.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>async def async_fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"\n    Asynchronously fits the model to the provided data.\n\n    Args:\n        x (_ARRAY): The independent variable data.\n        data (_ARRAY): The dependent variable data to fit.\n        mask (Optional[Union[_ARRAY, float]], optional): An optional mask to apply to the data. Defaults to None.\n        guess (Optional[_T], optional): An optional initial guess for the fitting parameters. Defaults to None.\n        **kwargs: Additional keyword arguments to pass to the fitting function.\n\n    Returns:\n        FitWithErrorResult[_T]:\n            The result of the fitting process, including the fitted parameters and associated errors.\n    \"\"\"\n    return self.fit(\n        x, data, mask=mask, guess=guess, method=method, maxfev=maxfev, **kwargs\n    )\n</code></pre>"},{"location":"functions/hyperbola/#ffit.funcs.hyperbola.Hyperbola.guess","title":"guess  <code>classmethod</code>","text":"<pre><code>guess(x, data, mask=None, guess=None, **kwargs)\n</code></pre> <p>Guess the initial fit parameters.</p> <p>This function returns an object of the class <code>FitResult</code>. See its documentation for more information on what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>The independent variable.</p> required <code>data</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>The initial guess for the fit parameters (optional).</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The guess, including the guess parameters and the function based on the guess.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n&gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n&gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n&gt;&gt;&gt; fit_guess.plot()\n</code></pre> Source code in <code>ffit/fit_logic.py</code> <pre><code>@classmethod\ndef guess(\n    cls,\n    x,\n    data,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Guess the initial fit parameters.\n\n    This function returns an object of the class `FitResult`.\n    See its documentation for more information on what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for the fit parameters (optional).\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The guess, including the guess parameters and the function based on the guess.\n\n    Examples:\n        &gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n        &gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n        &gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n        &gt;&gt;&gt; fit_guess.plot()\n    \"\"\"\n    if guess is not None:\n        return cls._result_class(\n            np.asarray(guess),\n            lambda x: cls.func(x, *guess),\n            x=x,\n            data=data,\n        )\n    x_masked, data_masked = get_masked_data(x, data, mask, mask_min_len=1)\n    guess_param = cls._guess(x_masked, data_masked, **kwargs)\n    return cls._result_class(\n        np.asarray(guess_param),\n        lambda x: cls.func(x, *guess_param),\n        x=x,\n        data=data,\n    )\n</code></pre>"},{"location":"functions/hyperbola/#ffit.funcs.hyperbola.Hyperbola.bootstrapping","title":"bootstrapping","text":"<pre><code>bootstrapping(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, maxfev=_DEFAULT_MAXFEV, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, _ANY_LIST_LIKE]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>The number of permutations to use for the bootstrapping.</p> <code>None</code> <code>maxfev</code> <code>int</code> <p>The maximum number of function evaluations.</p> <code>_DEFAULT_MAXFEV</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, _ANY_LIST_LIKE]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    maxfev: int = _DEFAULT_MAXFEV,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        num_of_permutations: The number of permutations to use for the bootstrapping.\n        maxfev: The maximum number of function evaluations.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    res_means, total_std = self._bootstrapping(\n        x, data, mask, guess, method, num_of_permutations, maxfev\n    )\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/hyperbola/#ffit.funcs.hyperbola.Hyperbola.array_bootstrapping","title":"array_bootstrapping","text":"<pre><code>array_bootstrapping(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, num_of_permutations=None, **kwargs)\n</code></pre> <p>Perform array bootstrapping in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>Number of bootstrap iterations.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the bootstrapping.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def array_bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array bootstrapping in parallel.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        num_of_permutations: Number of bootstrap iterations.\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the bootstrapping.\n    \"\"\"\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Run bootstrapping on each dataset\n    results = np.array(\n        [\n            self._bootstrapping(\n                x[i] if multi_x else x,\n                data[i],\n                mask=mask,\n                guess=guess,\n                method=method,\n                num_of_permutations=num_of_permutations,\n                maxfev=maxfev,\n                **kwargs,\n            )\n            for i in range(len(data))\n        ]\n    )\n\n    # Split means and stds from results\n    result_means = results[:, 0, :]  # First element of each result is means\n    result_stds = results[:, 1, :]  # Second element is standard deviations\n\n    # Reshape results back to original data shape\n    result_means = result_means.reshape(data_shape[:-1] + (-1,))\n    result_stds = result_stds.reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        result_means,\n        self._create_array_res_func(\n            result_means, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        stderr=result_stds,\n        stdfunc=lambda x: self.get_func_std()(x, *result_means, *result_stds),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/hyperbola/#ffit.funcs.hyperbola.Hyperbola.bootstrapping2D","title":"bootstrapping2D","text":"<pre><code>bootstrapping2D(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The 2D dependent variable (data, batches).</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping2D(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The 2D dependent variable (data, batches).\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    # Mask the data and check that length of masked data is greater than lens of params\n    x_masked, data_masked = get_masked_data(x, data, mask, self._param_len)\n    if len(x_masked) == 0 or len(data_masked) == 0:\n        return self._result_class(\n            np.ones(self._param_len) * np.nan,\n            x=x,\n            data=data,\n        )\n\n    # Get a guess if not provided\n    if guess is None:\n        guess = self._guess(x_masked, np.mean(data_masked, axis=-1), **kwargs)\n\n    # Fit ones to get the best initial guess\n    guess, cov = self._run_fit(\n        x_masked, np.mean(data_masked, axis=-1), guess, method\n    )\n\n    # Run fit on random subarrays\n    all_res = []\n    total_elements = data_masked.shape[1]\n    if num_of_permutations is None:\n        num_of_permutations = int(min(max(total_elements / 10, 1_000), 5_000))\n\n    for selected_index in bootstrap_generator(total_elements, num_of_permutations):\n        res, _ = self._run_fit(\n            x_masked,\n            np.mean(data_masked[:, selected_index], axis=-1),\n            guess,\n            method,\n        )\n        if self.normalize_res is not None:  # type: ignore\n            res = self.normalize_res(res)  # type: ignore\n        all_res.append(res)\n\n    res_means = np.mean(all_res, axis=0)\n    bootstrap_std = np.std(all_res, axis=0)\n    total_std = bootstrap_std\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        cov=cov,  # type: ignore\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/hyperbola/#ffit.funcs.hyperbola.Hyperbola.mp_array_fit","title":"mp_array_fit","text":"<pre><code>mp_array_fit(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, n_jobs=None, **kwargs)\n</code></pre> <p>Perform array fitting in parallel using multiprocessing.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>n_jobs</code> <code>Optional[int]</code> <p>Number of processes to use. If None, uses cpu_count().</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def mp_array_fit(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_t.Union[_ARRAY, float]] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    n_jobs: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array fitting in parallel using multiprocessing.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        n_jobs: Number of processes to use. If None, uses cpu_count().\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the fit.\n    \"\"\"\n    import multiprocessing as mp\n\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Prepare arguments for parallel processing\n    fit_args = [\n        (x[i] if multi_x else x, data[i], mask, guess, method, maxfev, kwargs)\n        for i in range(len(data))\n    ]\n\n    # Run fits in parallel using multiprocessing\n    with mp.Pool(processes=n_jobs) as pool:\n        results = pool.map(self._fit_worker, fit_args)\n\n    results = np.array(results).reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        results,\n        self._create_array_res_func(\n            results, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/line/","title":"Line","text":""},{"location":"functions/line/#simples-example","title":"Simples example","text":"<pre><code>&gt;&gt;&gt; from ffit.funcs.line import Line\n\n# Call the fit method with x and y data.\n&gt;&gt;&gt; fit_result = Line().fit(x, y)\n\n# The result is a FitResult object that can be unpacked.\n&gt;&gt;&gt; res, res_func = fit_result.res_and_func()\n\n# The parameters can be accessed as attributes.\n&gt;&gt; offset = fit_result.offset\n\n# One can combine multiple calls in one line.\n&gt;&gt;&gt; res = Line().fit(x, y, guess=[1, 2, 3, 4]).plot(ax)\n</code></pre>"},{"location":"functions/line/#final-parameters","title":"Final parameters","text":"<p>Line parameters.</p> Source code in <code>ffit/funcs/line.py</code> <pre><code>class LineParam(_t.Generic[_T], FuncParamClass):\n    \"\"\"Line parameters.\n\n    Attributes:\n        offset (float)\n        amplitude (float)\n    \"\"\"\n\n    keys = (\"offset\", \"amplitude\")\n\n    offset: _T\n    amplitude: _T\n\n    __latex_repr__ = r\"$&amp;offset + &amp;amplitude \\cdot x$\"\n    __latex_repr_symbols__ = {\n        \"offset\": r\"b\",\n        \"amplitude\": r\"a\",\n    }\n</code></pre>"},{"location":"functions/line/#ffit.funcs.line.Line--line-function","title":"Line function.","text":"\\[ f(x) = a_0 + a_1 * x \\] <pre><code>f(x) = offset + amplitude * x\n</code></pre>"},{"location":"functions/line/#ffit.funcs.line.Line--final-parameters","title":"Final parameters:","text":"<p>The final parameters are given by <code>LineParam</code> dataclass.</p> Source code in <code>ffit/funcs/line.py</code> <pre><code>class Line(FitLogic[LineResult]):  # type: ignore\n    r\"\"\"Line function.\n    ---------\n\n    $$\n    f(x) = a_0 + a_1 * x\n    $$\n\n        f(x) = offset + amplitude * x\n\n    Final parameters:\n    -----------------\n    The final parameters are given by [`LineParam`](../line_param/) dataclass.\n\n\n    \"\"\"\n\n    _result_class: _t.Type[LineResult] = LineResult\n    func = staticmethod(line_func)\n    _guess = staticmethod(line_guess)\n\n    _example_param = (1, 3)\n\n    @_t.overload\n    @classmethod\n    def mask(  # type: ignore # pylint: disable=W0221\n        cls,\n        *,\n        offset: float = None,  # type: ignore\n        amplitude: float = None,  # type: ignore\n    ) -&gt; \"Line\": ...\n\n    @classmethod\n    def mask(cls, **kwargs) -&gt; \"Line\":\n        return super().mask(**kwargs)\n</code></pre>"},{"location":"functions/line/#ffit.funcs.line.Line.fit","title":"fit","text":"<pre><code>fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n    if len(x) != len(data):\n        raise ValueError(\"x and data must have the same length\")\n    if mask is not None and len(mask) != len(x):\n        raise ValueError(\"mask must have the same length as x and data\")\n\n    res, res_std = self._fit(\n        x,\n        data,\n        mask=mask,\n        guess=guess,\n        method=method,\n        maxfev=maxfev,\n        **kwargs,\n    )\n\n    # param = self.param(*res, std=res_std)\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    # print(res)\n    return self._result_class(\n        res,\n        lambda x: full_func(x, *res),\n        std=res_std,\n        x=x,\n        data=data,\n        stderr=res_std,\n        stdfunc=lambda x: self.get_func_std()(x, *res, *res_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/line/#ffit.funcs.line.Line.async_fit","title":"async_fit  <code>async</code>","text":"<pre><code>async_fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Asynchronously fits the model to the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable data.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable data to fit.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>An optional mask to apply to the data. Defaults to None.</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>An optional initial guess for the fitting parameters. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the fitting function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>_T</code> <p>FitWithErrorResult[_T]: The result of the fitting process, including the fitted parameters and associated errors.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>async def async_fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"\n    Asynchronously fits the model to the provided data.\n\n    Args:\n        x (_ARRAY): The independent variable data.\n        data (_ARRAY): The dependent variable data to fit.\n        mask (Optional[Union[_ARRAY, float]], optional): An optional mask to apply to the data. Defaults to None.\n        guess (Optional[_T], optional): An optional initial guess for the fitting parameters. Defaults to None.\n        **kwargs: Additional keyword arguments to pass to the fitting function.\n\n    Returns:\n        FitWithErrorResult[_T]:\n            The result of the fitting process, including the fitted parameters and associated errors.\n    \"\"\"\n    return self.fit(\n        x, data, mask=mask, guess=guess, method=method, maxfev=maxfev, **kwargs\n    )\n</code></pre>"},{"location":"functions/line/#ffit.funcs.line.Line.guess","title":"guess  <code>classmethod</code>","text":"<pre><code>guess(x, data, mask=None, guess=None, **kwargs)\n</code></pre> <p>Guess the initial fit parameters.</p> <p>This function returns an object of the class <code>FitResult</code>. See its documentation for more information on what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>The independent variable.</p> required <code>data</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>The initial guess for the fit parameters (optional).</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The guess, including the guess parameters and the function based on the guess.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n&gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n&gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n&gt;&gt;&gt; fit_guess.plot()\n</code></pre> Source code in <code>ffit/fit_logic.py</code> <pre><code>@classmethod\ndef guess(\n    cls,\n    x,\n    data,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Guess the initial fit parameters.\n\n    This function returns an object of the class `FitResult`.\n    See its documentation for more information on what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for the fit parameters (optional).\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The guess, including the guess parameters and the function based on the guess.\n\n    Examples:\n        &gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n        &gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n        &gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n        &gt;&gt;&gt; fit_guess.plot()\n    \"\"\"\n    if guess is not None:\n        return cls._result_class(\n            np.asarray(guess),\n            lambda x: cls.func(x, *guess),\n            x=x,\n            data=data,\n        )\n    x_masked, data_masked = get_masked_data(x, data, mask, mask_min_len=1)\n    guess_param = cls._guess(x_masked, data_masked, **kwargs)\n    return cls._result_class(\n        np.asarray(guess_param),\n        lambda x: cls.func(x, *guess_param),\n        x=x,\n        data=data,\n    )\n</code></pre>"},{"location":"functions/line/#ffit.funcs.line.Line.bootstrapping","title":"bootstrapping","text":"<pre><code>bootstrapping(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, maxfev=_DEFAULT_MAXFEV, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, _ANY_LIST_LIKE]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>The number of permutations to use for the bootstrapping.</p> <code>None</code> <code>maxfev</code> <code>int</code> <p>The maximum number of function evaluations.</p> <code>_DEFAULT_MAXFEV</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, _ANY_LIST_LIKE]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    maxfev: int = _DEFAULT_MAXFEV,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        num_of_permutations: The number of permutations to use for the bootstrapping.\n        maxfev: The maximum number of function evaluations.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    res_means, total_std = self._bootstrapping(\n        x, data, mask, guess, method, num_of_permutations, maxfev\n    )\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/line/#ffit.funcs.line.Line.array_bootstrapping","title":"array_bootstrapping","text":"<pre><code>array_bootstrapping(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, num_of_permutations=None, **kwargs)\n</code></pre> <p>Perform array bootstrapping in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>Number of bootstrap iterations.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the bootstrapping.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def array_bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array bootstrapping in parallel.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        num_of_permutations: Number of bootstrap iterations.\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the bootstrapping.\n    \"\"\"\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Run bootstrapping on each dataset\n    results = np.array(\n        [\n            self._bootstrapping(\n                x[i] if multi_x else x,\n                data[i],\n                mask=mask,\n                guess=guess,\n                method=method,\n                num_of_permutations=num_of_permutations,\n                maxfev=maxfev,\n                **kwargs,\n            )\n            for i in range(len(data))\n        ]\n    )\n\n    # Split means and stds from results\n    result_means = results[:, 0, :]  # First element of each result is means\n    result_stds = results[:, 1, :]  # Second element is standard deviations\n\n    # Reshape results back to original data shape\n    result_means = result_means.reshape(data_shape[:-1] + (-1,))\n    result_stds = result_stds.reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        result_means,\n        self._create_array_res_func(\n            result_means, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        stderr=result_stds,\n        stdfunc=lambda x: self.get_func_std()(x, *result_means, *result_stds),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/line/#ffit.funcs.line.Line.bootstrapping2D","title":"bootstrapping2D","text":"<pre><code>bootstrapping2D(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The 2D dependent variable (data, batches).</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping2D(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The 2D dependent variable (data, batches).\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    # Mask the data and check that length of masked data is greater than lens of params\n    x_masked, data_masked = get_masked_data(x, data, mask, self._param_len)\n    if len(x_masked) == 0 or len(data_masked) == 0:\n        return self._result_class(\n            np.ones(self._param_len) * np.nan,\n            x=x,\n            data=data,\n        )\n\n    # Get a guess if not provided\n    if guess is None:\n        guess = self._guess(x_masked, np.mean(data_masked, axis=-1), **kwargs)\n\n    # Fit ones to get the best initial guess\n    guess, cov = self._run_fit(\n        x_masked, np.mean(data_masked, axis=-1), guess, method\n    )\n\n    # Run fit on random subarrays\n    all_res = []\n    total_elements = data_masked.shape[1]\n    if num_of_permutations is None:\n        num_of_permutations = int(min(max(total_elements / 10, 1_000), 5_000))\n\n    for selected_index in bootstrap_generator(total_elements, num_of_permutations):\n        res, _ = self._run_fit(\n            x_masked,\n            np.mean(data_masked[:, selected_index], axis=-1),\n            guess,\n            method,\n        )\n        if self.normalize_res is not None:  # type: ignore\n            res = self.normalize_res(res)  # type: ignore\n        all_res.append(res)\n\n    res_means = np.mean(all_res, axis=0)\n    bootstrap_std = np.std(all_res, axis=0)\n    total_std = bootstrap_std\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        cov=cov,  # type: ignore\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/line/#ffit.funcs.line.Line.mp_array_fit","title":"mp_array_fit","text":"<pre><code>mp_array_fit(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, n_jobs=None, **kwargs)\n</code></pre> <p>Perform array fitting in parallel using multiprocessing.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>n_jobs</code> <code>Optional[int]</code> <p>Number of processes to use. If None, uses cpu_count().</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def mp_array_fit(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_t.Union[_ARRAY, float]] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    n_jobs: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array fitting in parallel using multiprocessing.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        n_jobs: Number of processes to use. If None, uses cpu_count().\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the fit.\n    \"\"\"\n    import multiprocessing as mp\n\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Prepare arguments for parallel processing\n    fit_args = [\n        (x[i] if multi_x else x, data[i], mask, guess, method, maxfev, kwargs)\n        for i in range(len(data))\n    ]\n\n    # Run fits in parallel using multiprocessing\n    with mp.Pool(processes=n_jobs) as pool:\n        results = pool.map(self._fit_worker, fit_args)\n\n    results = np.array(results).reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        results,\n        self._create_array_res_func(\n            results, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/log/","title":"Log","text":""},{"location":"functions/log/#simples-example","title":"Simples example","text":"<pre><code>&gt;&gt;&gt; from ffit.funcs.log import Log\n\n# Call the fit method with x and y data.\n&gt;&gt;&gt; fit_result = Log().fit(x, y)\n\n# The result is a FitResult object that can be unpacked.\n&gt;&gt;&gt; res, res_func = fit_result.res_and_func()\n\n# The parameters can be accessed as attributes.\n&gt;&gt; amplitude = fit_result.amplitude\n\n# One can combine multiple calls in one line.\n&gt;&gt;&gt; res = Log().fit(x, y, guess=[1, 2, 3, 4]).plot(ax)\n</code></pre>"},{"location":"functions/log/#final-parameters","title":"Final parameters","text":"<p>Log parameters.</p> <p>Attributes:</p> Name Type Description <code>amplitude</code> <code>float</code> <p>The amplitude of the logarithm function.</p> <code>rate</code> <code>float</code> <p>The rate of the logarithm function.</p> <code>offset</code> <code>float</code> <p>The offset at x=1.</p>"},{"location":"functions/log/#ffit.funcs.log.LogParam--methods","title":"Methods:","text":"<ul> <li><code>amplitude_at_base(base: float = 10)</code>: float.     Return the amplitude if the base is not natural.</li> <li><code>offset_at_base(base: float = 10)</code>: float.     Return the offset if the base is not natural.</li> </ul> Source code in <code>ffit/funcs/log.py</code> <pre><code>class LogParam(_t.Generic[_T], FuncParamClass):\n    \"\"\"Log parameters.\n\n    Attributes:\n        amplitude (float):\n            The amplitude of the logarithm function.\n        rate (float):\n            The rate of the logarithm function.\n        offset (float):\n            The offset at x=1.\n\n    Methods:\n    -------\n    - `amplitude_at_base(base: float = 10)`: float.\n        Return the amplitude if the base is not natural.\n    - `offset_at_base(base: float = 10)`: float.\n        Return the offset if the base is not natural.\n    \"\"\"\n\n    keys = (\"amplitude\", \"rate\", \"offset\")\n\n    amplitude: _T\n    rate: _T\n    offset: _T\n\n    __latex_repr__ = r\"$&amp;amplitude \\cdot \\ln(&amp;rate \\cdot x) + &amp;offset$\"\n    __latex_repr_symbols__ = {\n        \"amplitude\": r\"A\",\n        \"rate\": r\"b\",\n        \"offset\": r\"A_0\",\n    }\n\n    def amplitude_at_base(self, base: float = 10) -&gt; _T:\n        return self.amplitude / np.log(base)  # pylint: disable=E1101\n\n    def offset_at_base(self, base: float = 10) -&gt; _T:\n        return self.offset + self.amplitude * np.log(  # pylint: disable=E1101 # type: ignore\n            self.rate  # pylint: disable=E1101 # type: ignore\n        ) * (1 / np.log(base) - 1)\n</code></pre>"},{"location":"functions/log/#ffit.funcs.log.Log--log-function","title":"Log function.","text":"\\[     f(x) = A * \\ln(b*x)) + A_0 \\] <pre><code>f(x) = amplitude * np.log(rate*x) + offset\n</code></pre>"},{"location":"functions/log/#ffit.funcs.log.Log--random-base","title":"Random base","text":"<p>For function with the random base of the logarithm: $$     f(x) &amp;= A * \\log_d(bx) + A_0 - A \\         &amp;= \\frac{A}{\\ln(d)} * \\ln(bx) + A_0 $$</p> <p>One can use <code>amplitude_at_base</code> method on the result to get the amplitude in random base.</p>"},{"location":"functions/log/#ffit.funcs.log.Log--final-parameters","title":"Final parameters","text":"<p>The final parameters are given by <code>LogParam</code> dataclass.</p> Source code in <code>ffit/funcs/log.py</code> <pre><code>class Log(FitLogic[LogResult]):  # type: ignore\n    r\"\"\"Log function.\n    ---------\n    $$\n        f(x) = A * \\ln(b*x)) + A_0\n    $$\n\n        f(x) = amplitude * np.log(rate*x) + offset\n\n    Random base\n    ------------\n\n    For function with the random base of the logarithm:\n    $$\n        f(x) &amp;= A * \\log_d(b*x) + A_0 - A \\\\\n            &amp;= \\frac{A}{\\ln(d)} * \\ln(b*x) + A_0\n    $$\n\n    One can use `amplitude_at_base` method on the result to get the amplitude in random base.\n\n\n    Final parameters\n    -----------------\n    The final parameters are given by [`LogParam`](../log_param/) dataclass.\n\n    \"\"\"\n\n    _result_class: _t.Type[LogResult] = LogResult\n\n    func = staticmethod(ln_func)\n    _guess = staticmethod(log_guess)\n\n    _example_param = (3, 0.5, 3)\n    _example_x_min = 1\n    _example_x_max = 5\n\n    _range_x = (1e-5, np.inf)  # type: ignore # np.finfo(float).eps\n    _test_rtol = 0.5\n\n    @_t.overload\n    @classmethod\n    def mask(  # type: ignore # pylint: disable=W0221\n        cls,\n        *,\n        amplitude: float = None,  # type: ignore\n        rate: float = None,  # type: ignore\n        offset: float = None,  # type: ignore\n    ) -&gt; \"Log\": ...\n\n    @classmethod\n    def mask(cls, **kwargs) -&gt; \"Log\":\n        return super().mask(**kwargs)\n</code></pre>"},{"location":"functions/log/#ffit.funcs.log.Log.fit","title":"fit","text":"<pre><code>fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n    if len(x) != len(data):\n        raise ValueError(\"x and data must have the same length\")\n    if mask is not None and len(mask) != len(x):\n        raise ValueError(\"mask must have the same length as x and data\")\n\n    res, res_std = self._fit(\n        x,\n        data,\n        mask=mask,\n        guess=guess,\n        method=method,\n        maxfev=maxfev,\n        **kwargs,\n    )\n\n    # param = self.param(*res, std=res_std)\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    # print(res)\n    return self._result_class(\n        res,\n        lambda x: full_func(x, *res),\n        std=res_std,\n        x=x,\n        data=data,\n        stderr=res_std,\n        stdfunc=lambda x: self.get_func_std()(x, *res, *res_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/log/#ffit.funcs.log.Log.async_fit","title":"async_fit  <code>async</code>","text":"<pre><code>async_fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Asynchronously fits the model to the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable data.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable data to fit.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>An optional mask to apply to the data. Defaults to None.</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>An optional initial guess for the fitting parameters. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the fitting function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>_T</code> <p>FitWithErrorResult[_T]: The result of the fitting process, including the fitted parameters and associated errors.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>async def async_fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"\n    Asynchronously fits the model to the provided data.\n\n    Args:\n        x (_ARRAY): The independent variable data.\n        data (_ARRAY): The dependent variable data to fit.\n        mask (Optional[Union[_ARRAY, float]], optional): An optional mask to apply to the data. Defaults to None.\n        guess (Optional[_T], optional): An optional initial guess for the fitting parameters. Defaults to None.\n        **kwargs: Additional keyword arguments to pass to the fitting function.\n\n    Returns:\n        FitWithErrorResult[_T]:\n            The result of the fitting process, including the fitted parameters and associated errors.\n    \"\"\"\n    return self.fit(\n        x, data, mask=mask, guess=guess, method=method, maxfev=maxfev, **kwargs\n    )\n</code></pre>"},{"location":"functions/log/#ffit.funcs.log.Log.guess","title":"guess  <code>classmethod</code>","text":"<pre><code>guess(x, data, mask=None, guess=None, **kwargs)\n</code></pre> <p>Guess the initial fit parameters.</p> <p>This function returns an object of the class <code>FitResult</code>. See its documentation for more information on what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>The independent variable.</p> required <code>data</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>The initial guess for the fit parameters (optional).</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The guess, including the guess parameters and the function based on the guess.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n&gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n&gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n&gt;&gt;&gt; fit_guess.plot()\n</code></pre> Source code in <code>ffit/fit_logic.py</code> <pre><code>@classmethod\ndef guess(\n    cls,\n    x,\n    data,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Guess the initial fit parameters.\n\n    This function returns an object of the class `FitResult`.\n    See its documentation for more information on what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for the fit parameters (optional).\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The guess, including the guess parameters and the function based on the guess.\n\n    Examples:\n        &gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n        &gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n        &gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n        &gt;&gt;&gt; fit_guess.plot()\n    \"\"\"\n    if guess is not None:\n        return cls._result_class(\n            np.asarray(guess),\n            lambda x: cls.func(x, *guess),\n            x=x,\n            data=data,\n        )\n    x_masked, data_masked = get_masked_data(x, data, mask, mask_min_len=1)\n    guess_param = cls._guess(x_masked, data_masked, **kwargs)\n    return cls._result_class(\n        np.asarray(guess_param),\n        lambda x: cls.func(x, *guess_param),\n        x=x,\n        data=data,\n    )\n</code></pre>"},{"location":"functions/log/#ffit.funcs.log.Log.bootstrapping","title":"bootstrapping","text":"<pre><code>bootstrapping(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, maxfev=_DEFAULT_MAXFEV, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, _ANY_LIST_LIKE]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>The number of permutations to use for the bootstrapping.</p> <code>None</code> <code>maxfev</code> <code>int</code> <p>The maximum number of function evaluations.</p> <code>_DEFAULT_MAXFEV</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, _ANY_LIST_LIKE]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    maxfev: int = _DEFAULT_MAXFEV,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        num_of_permutations: The number of permutations to use for the bootstrapping.\n        maxfev: The maximum number of function evaluations.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    res_means, total_std = self._bootstrapping(\n        x, data, mask, guess, method, num_of_permutations, maxfev\n    )\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/log/#ffit.funcs.log.Log.array_bootstrapping","title":"array_bootstrapping","text":"<pre><code>array_bootstrapping(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, num_of_permutations=None, **kwargs)\n</code></pre> <p>Perform array bootstrapping in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>Number of bootstrap iterations.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the bootstrapping.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def array_bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array bootstrapping in parallel.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        num_of_permutations: Number of bootstrap iterations.\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the bootstrapping.\n    \"\"\"\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Run bootstrapping on each dataset\n    results = np.array(\n        [\n            self._bootstrapping(\n                x[i] if multi_x else x,\n                data[i],\n                mask=mask,\n                guess=guess,\n                method=method,\n                num_of_permutations=num_of_permutations,\n                maxfev=maxfev,\n                **kwargs,\n            )\n            for i in range(len(data))\n        ]\n    )\n\n    # Split means and stds from results\n    result_means = results[:, 0, :]  # First element of each result is means\n    result_stds = results[:, 1, :]  # Second element is standard deviations\n\n    # Reshape results back to original data shape\n    result_means = result_means.reshape(data_shape[:-1] + (-1,))\n    result_stds = result_stds.reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        result_means,\n        self._create_array_res_func(\n            result_means, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        stderr=result_stds,\n        stdfunc=lambda x: self.get_func_std()(x, *result_means, *result_stds),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/log/#ffit.funcs.log.Log.bootstrapping2D","title":"bootstrapping2D","text":"<pre><code>bootstrapping2D(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The 2D dependent variable (data, batches).</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping2D(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The 2D dependent variable (data, batches).\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    # Mask the data and check that length of masked data is greater than lens of params\n    x_masked, data_masked = get_masked_data(x, data, mask, self._param_len)\n    if len(x_masked) == 0 or len(data_masked) == 0:\n        return self._result_class(\n            np.ones(self._param_len) * np.nan,\n            x=x,\n            data=data,\n        )\n\n    # Get a guess if not provided\n    if guess is None:\n        guess = self._guess(x_masked, np.mean(data_masked, axis=-1), **kwargs)\n\n    # Fit ones to get the best initial guess\n    guess, cov = self._run_fit(\n        x_masked, np.mean(data_masked, axis=-1), guess, method\n    )\n\n    # Run fit on random subarrays\n    all_res = []\n    total_elements = data_masked.shape[1]\n    if num_of_permutations is None:\n        num_of_permutations = int(min(max(total_elements / 10, 1_000), 5_000))\n\n    for selected_index in bootstrap_generator(total_elements, num_of_permutations):\n        res, _ = self._run_fit(\n            x_masked,\n            np.mean(data_masked[:, selected_index], axis=-1),\n            guess,\n            method,\n        )\n        if self.normalize_res is not None:  # type: ignore\n            res = self.normalize_res(res)  # type: ignore\n        all_res.append(res)\n\n    res_means = np.mean(all_res, axis=0)\n    bootstrap_std = np.std(all_res, axis=0)\n    total_std = bootstrap_std\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        cov=cov,  # type: ignore\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/log/#ffit.funcs.log.Log.mp_array_fit","title":"mp_array_fit","text":"<pre><code>mp_array_fit(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, n_jobs=None, **kwargs)\n</code></pre> <p>Perform array fitting in parallel using multiprocessing.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>n_jobs</code> <code>Optional[int]</code> <p>Number of processes to use. If None, uses cpu_count().</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def mp_array_fit(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_t.Union[_ARRAY, float]] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    n_jobs: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array fitting in parallel using multiprocessing.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        n_jobs: Number of processes to use. If None, uses cpu_count().\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the fit.\n    \"\"\"\n    import multiprocessing as mp\n\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Prepare arguments for parallel processing\n    fit_args = [\n        (x[i] if multi_x else x, data[i], mask, guess, method, maxfev, kwargs)\n        for i in range(len(data))\n    ]\n\n    # Run fits in parallel using multiprocessing\n    with mp.Pool(processes=n_jobs) as pool:\n        results = pool.map(self._fit_worker, fit_args)\n\n    results = np.array(results).reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        results,\n        self._create_array_res_func(\n            results, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/lorentzian/","title":"Lorentzian","text":""},{"location":"functions/lorentzian/#simples-example","title":"Simples example","text":"<pre><code>&gt;&gt;&gt; from ffit.funcs.lorentzian import Lorentzian\n\n# Call the fit method with x and y data.\n&gt;&gt;&gt; fit_result = Lorentzian().fit(x, y)\n\n# The result is a FitResult object that can be unpacked.\n&gt;&gt;&gt; res, res_func = fit_result.res_and_func()\n\n# The parameters can be accessed as attributes.\n&gt;&gt; amplitude = fit_result.amplitude\n\n# One can combine multiple calls in one line.\n&gt;&gt;&gt; res = Lorentzian().fit(x, y, guess=[1, 2, 3, 4]).plot(ax)\n</code></pre>"},{"location":"functions/lorentzian/#final-parameters","title":"Final parameters","text":"<p>Lorentzian parameters.</p> <p>Attributes:</p> Name Type Description <code>amplitude</code> <code>float</code> <p>The height of the peak.</p> <code>gamma</code> <code>float</code> <p>The half-width at half-maximum.</p> <code>x0</code> <code>float</code> <p>The position of the peak.</p> <code>offset</code> <code>float</code> <p>The baseline offset.</p> Additional attributes <p>sigma (float):     The full width at half-maximum.</p> Source code in <code>ffit/funcs/lorentzian.py</code> <pre><code>class LorentzianParam(_t.Generic[_T], FuncParamClass):\n    \"\"\"Lorentzian parameters.\n\n    Attributes:\n        amplitude (float):\n            The height of the peak.\n        gamma (float):\n            The half-width at half-maximum.\n        x0 (float):\n            The position of the peak.\n        offset (float):\n            The baseline offset.\n\n    Additional attributes:\n        sigma (float):\n            The full width at half-maximum.\n    \"\"\"\n\n    __slots__ = (\"amplitude\", \"gamma\", \"x0\", \"offset\")\n    keys = (\"amplitude\", \"gamma\", \"x0\", \"offset\")\n    amplitude: _T\n    gamma: _T\n    x0: _T\n    offset: _T\n\n    __latex_repr__ = (\n        r\"$&amp;amplitude \\cdot \\frac{&amp;gamma^2}{(x - &amp;x0)^2 + &amp;gamma^2} + &amp;offset$\"\n    )\n    __latex_repr_symbols__ = {\n        \"amplitude\": r\"A\",\n        \"gamma\": r\"\\gamma\",\n        \"x0\": r\"x_0\",\n        \"offset\": r\"b\",\n    }\n\n    @property\n    def sigma(self) -&gt; _T:\n        return self.gamma * 2  # type: ignore # pylint: disable=E1101\n</code></pre>"},{"location":"functions/lorentzian/#ffit.funcs.lorentzian.Lorentzian--lorentzian-function","title":"Lorentzian function.","text":"\\[ f(x) = A * \\frac{\\gamma^2}{(x-x_0)^2 + \\gamma^2} + A_0 \\] <pre><code>f(x) = amplitude * gamma**2 / ((x - x0) ** 2 + gamma**2) + offset\n</code></pre> <p>In this notation, the width at half-height: \\(\\sigma = 2\\gamma\\)</p>"},{"location":"functions/lorentzian/#ffit.funcs.lorentzian.Lorentzian--final-parameters","title":"Final parameters","text":"<p>The final parameters are given by <code>LorentzianParam</code> dataclass.</p> Source code in <code>ffit/funcs/lorentzian.py</code> <pre><code>class Lorentzian(FitLogic[LorentzianResult]):  # type: ignore\n    r\"\"\"Lorentzian function.\n    ---------\n\n    $$\n    f(x) = A * \\frac{\\gamma^2}{(x-x_0)^2 + \\gamma^2} + A_0\n    $$\n\n        f(x) = amplitude * gamma**2 / ((x - x0) ** 2 + gamma**2) + offset\n\n    In this notation, the width at half-height: $\\sigma = 2\\gamma$\n\n\n    Final parameters\n    -----------------\n    The final parameters are given by [`LorentzianParam`](../lorentzian_param/) dataclass.\n\n\n    \"\"\"\n\n    _result_class: _t.Type[LorentzianResult] = LorentzianResult\n\n    func = staticmethod(lorentzian_func)\n    _guess = staticmethod(lorentzian_guess)\n    normalize_res = staticmethod(normalize_res_list)\n\n    _example_param = (5, 1, 3, 2)\n    _example_x_min = 0\n    _example_x_max = 6\n\n    @_t.overload\n    @classmethod\n    def mask(  # type: ignore # pylint: disable=W0221\n        cls,\n        *,\n        amplitude: float = None,  # type: ignore\n        gamma: float = None,  # type: ignore\n        x0: float = None,  # type: ignore\n        offset: float = None,  # type: ignore\n    ) -&gt; \"Lorentzian\": ...\n\n    @classmethod\n    def mask(cls, **kwargs) -&gt; \"Lorentzian\":\n        return super().mask(**kwargs)\n</code></pre>"},{"location":"functions/lorentzian/#ffit.funcs.lorentzian.Lorentzian.fit","title":"fit","text":"<pre><code>fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n    if len(x) != len(data):\n        raise ValueError(\"x and data must have the same length\")\n    if mask is not None and len(mask) != len(x):\n        raise ValueError(\"mask must have the same length as x and data\")\n\n    res, res_std = self._fit(\n        x,\n        data,\n        mask=mask,\n        guess=guess,\n        method=method,\n        maxfev=maxfev,\n        **kwargs,\n    )\n\n    # param = self.param(*res, std=res_std)\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    # print(res)\n    return self._result_class(\n        res,\n        lambda x: full_func(x, *res),\n        std=res_std,\n        x=x,\n        data=data,\n        stderr=res_std,\n        stdfunc=lambda x: self.get_func_std()(x, *res, *res_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/lorentzian/#ffit.funcs.lorentzian.Lorentzian.async_fit","title":"async_fit  <code>async</code>","text":"<pre><code>async_fit(x, data, *, mask=None, guess=None, method='leastsq', maxfev=10000, **kwargs)\n</code></pre> <p>Asynchronously fits the model to the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable data.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable data to fit.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>An optional mask to apply to the data. Defaults to None.</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>An optional initial guess for the fitting parameters. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the fitting function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>_T</code> <p>FitWithErrorResult[_T]: The result of the fitting process, including the fitted parameters and associated errors.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>async def async_fit(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"\n    Asynchronously fits the model to the provided data.\n\n    Args:\n        x (_ARRAY): The independent variable data.\n        data (_ARRAY): The dependent variable data to fit.\n        mask (Optional[Union[_ARRAY, float]], optional): An optional mask to apply to the data. Defaults to None.\n        guess (Optional[_T], optional): An optional initial guess for the fitting parameters. Defaults to None.\n        **kwargs: Additional keyword arguments to pass to the fitting function.\n\n    Returns:\n        FitWithErrorResult[_T]:\n            The result of the fitting process, including the fitted parameters and associated errors.\n    \"\"\"\n    return self.fit(\n        x, data, mask=mask, guess=guess, method=method, maxfev=maxfev, **kwargs\n    )\n</code></pre>"},{"location":"functions/lorentzian/#ffit.funcs.lorentzian.Lorentzian.guess","title":"guess  <code>classmethod</code>","text":"<pre><code>guess(x, data, mask=None, guess=None, **kwargs)\n</code></pre> <p>Guess the initial fit parameters.</p> <p>This function returns an object of the class <code>FitResult</code>. See its documentation for more information on what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>The independent variable.</p> required <code>data</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[_T]</code> <p>The initial guess for the fit parameters (optional).</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The guess, including the guess parameters and the function based on the guess.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n&gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n&gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n&gt;&gt;&gt; fit_guess.plot()\n</code></pre> Source code in <code>ffit/fit_logic.py</code> <pre><code>@classmethod\ndef guess(\n    cls,\n    x,\n    data,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_T] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Guess the initial fit parameters.\n\n    This function returns an object of the class `FitResult`.\n    See its documentation for more information on what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for the fit parameters (optional).\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The guess, including the guess parameters and the function based on the guess.\n\n    Examples:\n        &gt;&gt;&gt; x = [1, 2, 3, 4, 5]\n        &gt;&gt;&gt; data = [2, 4, 6, 8, 10]\n        &gt;&gt;&gt; fit_guess = FitLogic.guess(x, data)\n        &gt;&gt;&gt; fit_guess.plot()\n    \"\"\"\n    if guess is not None:\n        return cls._result_class(\n            np.asarray(guess),\n            lambda x: cls.func(x, *guess),\n            x=x,\n            data=data,\n        )\n    x_masked, data_masked = get_masked_data(x, data, mask, mask_min_len=1)\n    guess_param = cls._guess(x_masked, data_masked, **kwargs)\n    return cls._result_class(\n        np.asarray(guess_param),\n        lambda x: cls.func(x, *guess_param),\n        x=x,\n        data=data,\n    )\n</code></pre>"},{"location":"functions/lorentzian/#ffit.funcs.lorentzian.Lorentzian.bootstrapping","title":"bootstrapping","text":"<pre><code>bootstrapping(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, maxfev=_DEFAULT_MAXFEV, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_ARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, _ANY_LIST_LIKE]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>The number of permutations to use for the bootstrapping.</p> <code>None</code> <code>maxfev</code> <code>int</code> <p>The maximum number of function evaluations.</p> <code>_DEFAULT_MAXFEV</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _ARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, _ANY_LIST_LIKE]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    maxfev: int = _DEFAULT_MAXFEV,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        num_of_permutations: The number of permutations to use for the bootstrapping.\n        maxfev: The maximum number of function evaluations.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    res_means, total_std = self._bootstrapping(\n        x, data, mask, guess, method, num_of_permutations, maxfev\n    )\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/lorentzian/#ffit.funcs.lorentzian.Lorentzian.array_bootstrapping","title":"array_bootstrapping","text":"<pre><code>array_bootstrapping(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, num_of_permutations=None, **kwargs)\n</code></pre> <p>Perform array bootstrapping in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>num_of_permutations</code> <code>Optional[int]</code> <p>Number of bootstrap iterations.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the bootstrapping.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def array_bootstrapping(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array bootstrapping in parallel.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        num_of_permutations: Number of bootstrap iterations.\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the bootstrapping.\n    \"\"\"\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Run bootstrapping on each dataset\n    results = np.array(\n        [\n            self._bootstrapping(\n                x[i] if multi_x else x,\n                data[i],\n                mask=mask,\n                guess=guess,\n                method=method,\n                num_of_permutations=num_of_permutations,\n                maxfev=maxfev,\n                **kwargs,\n            )\n            for i in range(len(data))\n        ]\n    )\n\n    # Split means and stds from results\n    result_means = results[:, 0, :]  # First element of each result is means\n    result_stds = results[:, 1, :]  # Second element is standard deviations\n\n    # Reshape results back to original data shape\n    result_means = result_means.reshape(data_shape[:-1] + (-1,))\n    result_stds = result_stds.reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        result_means,\n        self._create_array_res_func(\n            result_means, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        stderr=result_stds,\n        stdfunc=lambda x: self.get_func_std()(x, *result_means, *result_stds),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/lorentzian/#ffit.funcs.lorentzian.Lorentzian.bootstrapping2D","title":"bootstrapping2D","text":"<pre><code>bootstrapping2D(x, data, mask=None, guess=None, method='leastsq', num_of_permutations=None, **kwargs)\n</code></pre> <p>Fit the data using the specified fitting function.</p> <p>This function returns FitResult see the documentation for more information what is possible with it.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The 2D dependent variable (data, batches).</p> required <code>mask</code> <code>Optional[_ARRAY]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use. Valid options are \"least_squares\", \"leastsq\", and \"curve_fit\" (default: \"leastsq\").</p> <code>'leastsq'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit, including the fitted parameters and the fitted function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid fitting method is provided.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def bootstrapping2D(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    mask: _t.Optional[_ARRAY] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    num_of_permutations: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:  # Tuple[_T, _t.Callable, _NDARRAY]:\n    \"\"\"\n    Fit the data using the specified fitting function.\n\n    This function returns [FitResult][ffit.fit_results.FitResult] see\n    the documentation for more information what is possible with it.\n\n    Args:\n        x: The independent variable.\n        data: The 2D dependent variable (data, batches).\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        method: The fitting method to use. Valid options are \"least_squares\", \"leastsq\",\n            and \"curve_fit\" (default: \"leastsq\").\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        FitResult: The result of the fit, including the fitted parameters and the fitted function.\n\n    Raises:\n        ValueError: If an invalid fitting method is provided.\n\n    \"\"\"\n    # Convert x and data to numpy arrays\n    x, data = np.asarray(x), np.asarray(data)\n\n    # Mask the data and check that length of masked data is greater than lens of params\n    x_masked, data_masked = get_masked_data(x, data, mask, self._param_len)\n    if len(x_masked) == 0 or len(data_masked) == 0:\n        return self._result_class(\n            np.ones(self._param_len) * np.nan,\n            x=x,\n            data=data,\n        )\n\n    # Get a guess if not provided\n    if guess is None:\n        guess = self._guess(x_masked, np.mean(data_masked, axis=-1), **kwargs)\n\n    # Fit ones to get the best initial guess\n    guess, cov = self._run_fit(\n        x_masked, np.mean(data_masked, axis=-1), guess, method\n    )\n\n    # Run fit on random subarrays\n    all_res = []\n    total_elements = data_masked.shape[1]\n    if num_of_permutations is None:\n        num_of_permutations = int(min(max(total_elements / 10, 1_000), 5_000))\n\n    for selected_index in bootstrap_generator(total_elements, num_of_permutations):\n        res, _ = self._run_fit(\n            x_masked,\n            np.mean(data_masked[:, selected_index], axis=-1),\n            guess,\n            method,\n        )\n        if self.normalize_res is not None:  # type: ignore\n            res = self.normalize_res(res)  # type: ignore\n        all_res.append(res)\n\n    res_means = np.mean(all_res, axis=0)\n    bootstrap_std = np.std(all_res, axis=0)\n    total_std = bootstrap_std\n\n    full_func = getattr(self, \"full_func\", self.__class__().func)\n\n    return self._result_class(\n        res_means,\n        lambda x: full_func(x, *res_means),\n        x=x,\n        data=data,\n        cov=cov,  # type: ignore\n        stderr=total_std,  # type: ignore\n        stdfunc=lambda x: self.get_func_std()(x, *res_means, *total_std),\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"functions/lorentzian/#ffit.funcs.lorentzian.Lorentzian.mp_array_fit","title":"mp_array_fit","text":"<pre><code>mp_array_fit(x, data, *, mask=None, guess=None, axis=-1, method='leastsq', maxfev=10000, n_jobs=None, **kwargs)\n</code></pre> <p>Perform array fitting in parallel using multiprocessing.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_ARRAY</code> <p>The independent variable.</p> required <code>data</code> <code>_2DARRAY</code> <p>The dependent variable.</p> required <code>mask</code> <code>Optional[Union[_ARRAY, float]]</code> <p>The mask array or threshold for data filtering (optional).</p> <code>None</code> <code>guess</code> <code>Optional[Union[_T, tuple, list]]</code> <p>The initial guess for fit parameters (optional).</p> <code>None</code> <code>axis</code> <code>int</code> <p>The axis along which to perform the fit (default: -1).</p> <code>-1</code> <code>method</code> <code>Literal['least_squares', 'leastsq', 'curve_fit']</code> <p>The fitting method to use (default: \"leastsq\").</p> <code>'leastsq'</code> <code>maxfev</code> <code>int</code> <p>Maximum number of function evaluations (default: 10000).</p> <code>10000</code> <code>n_jobs</code> <code>Optional[int]</code> <p>Number of processes to use. If None, uses cpu_count().</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to _fit.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>FitResult</code> <code>_T</code> <p>The result of the fit.</p> Source code in <code>ffit/fit_logic.py</code> <pre><code>def mp_array_fit(\n    self,\n    x: _ARRAY,\n    data: _2DARRAY,\n    *,\n    mask: _t.Optional[_t.Union[_ARRAY, float]] = None,\n    guess: _t.Optional[_t.Union[_T, tuple, list]] = None,\n    axis: int = -1,\n    method: _t.Literal[\"least_squares\", \"leastsq\", \"curve_fit\"] = \"leastsq\",\n    maxfev: int = 10000,\n    n_jobs: _t.Optional[int] = None,\n    **kwargs,\n) -&gt; _T:\n    \"\"\"Perform array fitting in parallel using multiprocessing.\n\n    Args:\n        x: The independent variable.\n        data: The dependent variable.\n        mask: The mask array or threshold for data filtering (optional).\n        guess: The initial guess for fit parameters (optional).\n        axis: The axis along which to perform the fit (default: -1).\n        method: The fitting method to use (default: \"leastsq\").\n        maxfev: Maximum number of function evaluations (default: 10000).\n        n_jobs: Number of processes to use. If None, uses cpu_count().\n        **kwargs: Additional keyword arguments passed to _fit.\n\n    Returns:\n        FitResult: The result of the fit.\n    \"\"\"\n    import multiprocessing as mp\n\n    x, data, multi_x, data_shape, x_shape, selected_axis_len = (\n        self._prepare_array_data(x, data, axis)\n    )\n\n    # Prepare arguments for parallel processing\n    fit_args = [\n        (x[i] if multi_x else x, data[i], mask, guess, method, maxfev, kwargs)\n        for i in range(len(data))\n    ]\n\n    # Run fits in parallel using multiprocessing\n    with mp.Pool(processes=n_jobs) as pool:\n        results = pool.map(self._fit_worker, fit_args)\n\n    results = np.array(results).reshape(data_shape[:-1] + (-1,))\n\n    if multi_x:\n        x = x.reshape(x_shape)\n\n    return self._result_class(\n        results,\n        self._create_array_res_func(\n            results, multi_x, data_shape, selected_axis_len\n        ),\n        x=x,\n        data=data,\n        original_func=self.func,\n    )\n</code></pre>"},{"location":"releases/","title":"Release Notes","text":""},{"location":"releases/#110-2024-12-25-major-refactoring","title":"1.1.0 (2024-12-25) - Major Refactoring","text":"<p>Key Changes to <code>FitResult</code>:</p> <ul> <li><code>FitResult</code> is no longer a subclass of <code>tuple</code>. To achieve similar behavior and unpack <code>res</code> and <code>res_func</code>, use the new method <code>fit_result.res_and_func()</code>.</li> <li>All parameters are now directly accessible as attributes. Accessing parameters via <code>fit.res</code> is still possible but can be deprecated in the future.</li> <li>The <code>res</code> as np.ndarray is now accessible via <code>fit.res_array</code>.</li> <li>The <code>FitArrayResult</code> structure has been refactored and is now unified with <code>FitResult</code>.</li> <li>Results in <code>FitResult</code> are guaranteed to never be <code>None</code>. If the fit fails, each parameter will return <code>np.nan</code>, and the <code>success</code> attribute will be set to <code>False</code>.</li> </ul> <p>Other Changes:</p> <ul> <li><code>array_fit</code> can now be applied to any axes, offering greater flexibility.</li> <li>Each implemented fit function now has a dedicated result class with predefined slots and custom methods.</li> <li>The <code>leastsq</code> method has been removed. Without specifying an exact function, the <code>FitResult</code> for classical <code>leastsq</code> becomes useless. Use <code>curve_fit</code> instead, specifying <code>method='leastsq'</code>.</li> </ul> <p>Normally these changes only affect you if you unpack the <code>FitResult</code> before. We apologize for any inconvenience, but we believe these changes will improve the package's usability in the long run and should be made as soon as possible.</p>"},{"location":"releases/#100-2024-11-16","title":"1.0.0 (2024-11-16)","text":"<ul> <li>Automatic documentation generation for each function.</li> <li>Automated testing for all functions.</li> <li>New guide available for creating custom functions.</li> </ul>"},{"location":"releases/#020-2024-08-28","title":"0.2.0 (2024-08-28)","text":"<ul> <li>Beta version of the package.</li> </ul>"},{"location":"starting_guide/first_steps/","title":"Getting Started with <code>FFit</code>","text":"<p>Make sure you have installed the package before.</p> <p>Use any function from the list of implemented functions to fit your data or use your custom function.</p> <p>Any contribution is welcome. Please check the developer guidelines for more information.</p>"},{"location":"starting_guide/install/","title":"Installation <code>FFit</code>","text":"<p>You can install the <code>ffit</code> library using either pip or by pulling the repository directly from GitHub.</p>"},{"location":"starting_guide/install/#option-1-install-via-pip","title":"Option 1: Install via Pip","text":"<p>Open your terminal and run the following command</p> <pre><code>pip install ffit\n</code></pre>"},{"location":"starting_guide/install/#option-2-install-from-github","title":"Option 2: Install from GitHub","text":"<p>You can also install <code>ffit</code> directly from its GitHub repository. This option is useful if you want to work with the latest development version or if you need to customize the library. Here's how to do it:</p> <ol> <li>Clone the <code>ffit</code> repository from GitHub using the following command:</li> </ol> <pre><code>git clone https://github.com/kyrylo-gr/ffit.git\n</code></pre> <ol> <li>Enter the directory and install the package.</li> </ol> <pre><code>cd ffit\npip install -e .\n</code></pre> <p><code>-e</code> allows you to link the library to the directory that you created, therefore allows you to change the code inside this directory. Instead <code>pip install -e .</code> you can run <code>python setup.py develop</code> if you prefer.</p>"},{"location":"starting_guide/install/#thats-it","title":"That's it!","text":"<p>You've successfully installed the <code>ffit</code> library. You can now start incorporating <code>ffit</code> into your Python projects.</p> <p>For further insight, please refer to the First Steps guide.</p>"}]}